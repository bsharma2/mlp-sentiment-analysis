{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression for Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapted from http://nbviewer.jupyter.org/github/rasbt/pattern_classification/blob/master/machine_learning/scikit-learn/outofcore_modelpersistence.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The IMDb Movie Review Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will train a simple logistic regression model to classify movie reviews from the 50k IMDb review dataset that has been collected by Maas et. al.\n",
    "\n",
    "> AL Maas, RE Daly, PT Pham, D Huang, AY Ng, and C Potts. Learning word vectors for sentiment analysis. In Proceedings of the 49th Annual Meeting of the Association for Computational Lin- guistics: Human Language Technologies, pages 142â€“150, Portland, Oregon, USA, June 2011. Association for Computational Linguistics\n",
    "\n",
    "[Source: http://ai.stanford.edu/~amaas/data/sentiment/]\n",
    "\n",
    "The dataset consists of 50,000 movie reviews from the original \"train\" and \"test\" subdirectories. The class labels are binary (1=positive and 0=negative) and contain 25,000 positive and 25,000 negative movie reviews, respectively.\n",
    "For simplicity, I assembled the reviews in a single CSV file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import collections\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>OK, lets start with the best. the building. al...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>The British 'heritage film' industry is out of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I don't even know where to begin on this one. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>Richard Tyler is a little boy who is scared of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>I waited long to watch this movie. Also becaus...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment\n",
       "49995  OK, lets start with the best. the building. al...          0\n",
       "49996  The British 'heritage film' industry is out of...          0\n",
       "49997  I don't even know where to begin on this one. ...          0\n",
       "49998  Richard Tyler is a little boy who is scared of...          0\n",
       "49999  I waited long to watch this movie. Also becaus...          1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if you want to download the original file:\n",
    "#df = pd.read_csv('https://raw.githubusercontent.com/rasbt/pattern_classification/master/data/50k_imdb_movie_reviews.csv')\n",
    "# otherwise load local file\n",
    "df = pd.read_csv('shuffled_movie_data.csv')\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us shuffle the class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['In 1974, the teenager Martha Moxley (Maggie Grace) moves to the high-class area of Belle Haven, Greenwich, Connecticut. On the Mischief Night, eve of Halloween, she was murdered in the backyard of her house and her murder remained unsolved. Twenty-two years later, the writer Mark Fuhrman (Christopher Meloni), who is a former LA detective that has fallen in disgrace for perjury in O.J. Simpson trial and moved to Idaho, decides to investigate the case with his partner Stephen Weeks (Andrew Mitchell) with the purpose of writing a book. The locals squirm and do not welcome them, but with the support of the retired detective Steve Carroll (Robert Forster) that was in charge of the investigation in the 70\\'s, they discover the criminal and a net of power and money to cover the murder.<br /><br />\"Murder in Greenwich\" is a good TV movie, with the true story of a murder of a fifteen years old girl that was committed by a wealthy teenager whose mother was a Kennedy. The powerful and rich family used their influence to cover the murder for more than twenty years. However, a snoopy detective and convicted perjurer in disgrace was able to disclose how the hideous crime was committed. The screenplay shows the investigation of Mark and the last days of Martha in parallel, but there is a lack of the emotion in the dramatization. My vote is seven.<br /><br />Title (Brazil): Not Available',\n",
       "       1], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head().values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## uncomment these lines if you have dowloaded the original file:\n",
    "#np.random.seed(0)\n",
    "#df = df.reindex(np.random.permutation(df.index))\n",
    "#df[['review', 'sentiment']].to_csv('shuffled_movie_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us define a simple `tokenizer` that splits the text into individual word tokens. Furthermore, we will use some simple regular expression to remove HTML markup and all non-letter characters but \"emoticons,\" convert the text to lower case, remove stopwords, and apply the Porter stemming algorithm to convert the words into their root form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def tokenizer(text):\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text.lower())\n",
    "    text = re.sub('[\\W]+', ' ', text.lower())\n",
    "    text = [w for w in text.split()]\n",
    "    tokenized = [wordnet_lemmatizer.lemmatize(w) for w in text]\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's give it at try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this', 'is', 'a', 'test']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('This :) is a <a> test! :-)</br>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define a generator that returns the document body and the corresponding class label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_docs(path):\n",
    "    with open(path, 'r') as csv:\n",
    "        next(csv) # skip header\n",
    "        for line in csv:\n",
    "            text, label = line[:-3], int(line[-2])\n",
    "            yield text, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To conform that the `stream_docs` function fetches the documents as intended, let us execute the following code snippet before we implement the `get_minibatch` function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we confirmed that our `stream_docs` functions works, we will now implement a `get_minibatch` function to fetch a specified number (`size`) of documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_minibatch(doc_stream, size):\n",
    "    docs, y = [], []\n",
    "    for _ in range(size):\n",
    "        text, label = next(doc_stream)\n",
    "        docs.append(text)\n",
    "        y.append(label)\n",
    "    return docs, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will make use of the \"hashing trick\" through scikit-learns [HashingVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.HashingVectorizer.html) to create a bag-of-words model of our documents. Details of the bag-of-words model for document classification can be found at  [Naive Bayes and Text Classification I - Introduction and Theory](http://arxiv.org/abs/1410.5329)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: define features based on word embeddings (pre-trained word2vec / Glove/Fastext emebddings can be used)\n",
    "# Define suitable d dimension, and sequence length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train our own embedding vectors with all the reviews, with a 40 size of each vector to save memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_generator = stream_docs(path='shuffled_movie_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done     \n",
      "\n",
      "50000\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "doc_generator = stream_docs(path='shuffled_movie_data.csv')\n",
    "\n",
    "sentences = []\n",
    "labels    = []\n",
    "lengths   = []\n",
    "for idx, review in enumerate(doc_generator):\n",
    "    toVec = tokenizer(review[0])\n",
    "    sentences.append(toVec)\n",
    "    labels.append(review[1])\n",
    "    lengths.append(len(toVec))\n",
    "    sys.stdout.write('\\r{:5.2f}%'.format(100*(idx+1)/50000))\n",
    "sys.stdout.write('\\rDone     \\n\\n')  \n",
    "print(len(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting embedding vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained!\n"
     ]
    }
   ],
   "source": [
    "emb_size = 40\n",
    "\n",
    "model = Word2Vec(sentences, size=emb_size, window=5, min_count=5, workers=4)\n",
    "print('trained!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'woman' is similar to 'girl' with a score of 0.8877\n"
     ]
    }
   ],
   "source": [
    "sim = model.wv.most_similar(positive=['woman'], topn=1)\n",
    "print(\"'woman' is similar to '{}' with a score of {:1.4f}\".format(sim[0][0],sim[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary size : 35327\n"
     ]
    }
   ],
   "source": [
    "print('vocabulary size :', len(model.wv.vocab.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding size :  (40,)\n"
     ]
    }
   ],
   "source": [
    "print('embedding size : ', model.wv['woman'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewVectorizer:\n",
    "    def __init__(self, model, maxlen):\n",
    "        self.model  = model\n",
    "        self.maxlen = maxlen\n",
    "    def transform(self, reviews_tokenized):\n",
    "        n = len(reviews_tokenized)\n",
    "        vector = np.zeros((n, self.maxlen, emb_size), dtype=np.float16)\n",
    "        for idx, review in enumerate(reviews_tokenized):\n",
    "            for iw, word in enumerate(review):\n",
    "                if word in self.model.wv.vocab:\n",
    "                    vector[idx][iw] = self.model.wv[word]\n",
    "            sys.stdout.write('\\r{:5.2f}%'.format(100*(idx+1)/n))\n",
    "        sys.stdout.write('\\rDone     \\n\\n')                    \n",
    "        vector = vector.reshape((n, -1))\n",
    "        return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAXLEN = max(lengths)\n",
    "vectorizer = ReviewVectorizer(model, MAXLEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done     \n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = vectorizer.transform(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (MAXLEN*emb_size == res.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (50000, 99920)\n",
      "y_train shape:  (50000, 1)\n"
     ]
    }
   ],
   "source": [
    "y_train = np.asarray(labels).reshape((-1, 1))\n",
    "X_train = res\n",
    "del res\n",
    "print('X_train shape: ',X_train.shape)\n",
    "print('y_train shape: ',y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Define at least a Three layer neural network. Define its structure (number of hidden neurons, etc)\n",
    "# Define a nonlinear function for hidden layers.\n",
    "# Define a suitable loss function for binary classification\n",
    "# Implement the backpropagation algorithm for this structure\n",
    "# Do not use Keras / Tensorflow /PyTorch etc. libraries\n",
    "# Train the model using SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using 3 layers, 2 hidden layers with tangent hiperbolic activation and a sigmoid function at the end. This neural network also work with L1 and L2 regularization.\n",
    "\n",
    "We try to use few neurons on hidden layers to get a better generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Multilayer:\n",
    "    \"\"\"\n",
    "        Logistic Regression with L1 and L2 regularization\n",
    "        \n",
    "        Arguments:\n",
    "                \n",
    "                alpha   : Learning Rate\n",
    "                l1_coef : Lambda 1\n",
    "                l2_coef : Lambda 2\n",
    "            \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__ (self, input_size, hid_units1, hid_units2, lr, lambda_1, lambda_2):\n",
    "        self.W1      = np.random.randn(input_size, hid_units1) * np.sqrt(1/input_size)\n",
    "        self.b1      = np.zeros((1, hid_units1))\n",
    "        self.W2      = np.random.randn(hid_units1, hid_units2) * np.sqrt(1/hid_units1)\n",
    "        self.b2      = np.zeros((1, hid_units2))\n",
    "        self.W3      = np.random.randn(hid_units2,          1) * np.sqrt(1/hid_units2)\n",
    "        self.b3      = 0.0\n",
    "        self.lr      = lr\n",
    "        self.l1_coef = lambda_1\n",
    "        self.l2_coef = lambda_2\n",
    "        \n",
    "    def ReLU(self, z):\n",
    "        return np.maximum(0, z)\n",
    "    \n",
    "    def TangH(self, z):\n",
    "        return (np.exp(z) - np.exp(-z))/(np.exp(z) + np.exp(-z) + 1e-8)\n",
    "    \n",
    "    def deltaTangH(self, z):\n",
    "        return 4 * np.exp(z) * np.exp(-z)/(np.exp(z) + np.exp(-z)+ 1e-8)**2\n",
    "    \n",
    "    def sigmoid(self,z):\n",
    "        \"\"\"\n",
    "            Activation function\n",
    "            \n",
    "            Arguments:  \n",
    "                z : W*X + b\n",
    "                \n",
    "            Returns:\n",
    "                sigmoid function of z.\n",
    "                \n",
    "        \"\"\"\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    def deltaCost(self, y, y_hat):\n",
    "        return y_hat - y\n",
    "        \n",
    "    def pred(self, X):\n",
    "        \"\"\"\n",
    "            Given a X matrix as a input we return the prediction for\n",
    "            W and b.\n",
    "            \n",
    "            Args:\n",
    "                X : Matrix of features vectors for each review\n",
    "            \n",
    "            Returns:\n",
    "                Prediction without a threshold\n",
    "        \"\"\"\n",
    "        Z1 = np.dot(X , self.W1) + self.b1\n",
    "        A1 = self.TangH(Z1)\n",
    "        Z2 = np.dot(A1, self.W2) + self.b2\n",
    "        A2 = self.TangH(Z2)   \n",
    "        Z3 = np.dot(A2, self.W3) + self.b3\n",
    "        A3 = self.sigmoid(Z3)          \n",
    "        return A3\n",
    "\n",
    "    def predSentiment(self, X):\n",
    "        \"\"\"\n",
    "            Given a X matrix as a input we return the prediction with threshold \n",
    "            for W and b.\n",
    "            \n",
    "            Args:\n",
    "                X : Matrix of features vectors for each review\n",
    "            \n",
    "            Returns:\n",
    "                Prediction with threshold\n",
    "        \"\"\"\n",
    "        return self.pred(X) > 0.5\n",
    "    \n",
    "    def acc(self, X, y):\n",
    "        \"\"\"\n",
    "            Accuracy of a input and label\n",
    "            \n",
    "            Args:\n",
    "                X: Matrix of features vectors for each review\n",
    "                y: Labels of each Matrix\n",
    "            \n",
    "            Returns:\n",
    "                A number between 0 and 1.0\n",
    "        \"\"\"\n",
    "        \n",
    "        return np.mean(self.predSentiment(X) == y)\n",
    "    \n",
    "    def getCost(self,y, y_hat):\n",
    "        \"\"\"\n",
    "            Cost function\n",
    "            \n",
    "                Cost = - [y * log(sigma(W*X + b)) + (1 - y) * log(1 - sigma(W*X + b))] \n",
    "                         + 0.5 * l2_ratio * ||w||^2_2 \n",
    "                         + l1_ratio * ||w||_1 \n",
    "            \n",
    "            Args:\n",
    "                X: Matrix of features vectors for each review\n",
    "                y: Labels of each Matrix\n",
    "                \n",
    "            Returns:\n",
    "                Cost using L1 and L2 regularizations \n",
    "                \n",
    "        \"\"\"\n",
    "        y_hat = np.clip(y_hat, 1e-8, 1 - 1e-8)\n",
    "        cost  = - 0.5 * np.mean(np.multiply(y  , np.log(y_hat     + 1e-5))\n",
    "                             + np.multiply(1-y , np.log(1 - y_hat + 1e-5)))\n",
    "        \n",
    "        cost += 0.5 * self.l2_coef * np.sum(np.square(self.W1)) + self.l1_coef * np.sum(np.abs(self.W1)) \n",
    "        cost += 0.5 * self.l2_coef * np.sum(np.square(self.W2)) + self.l1_coef * np.sum(np.abs(self.W2))\n",
    "        \n",
    "        return cost \n",
    "    \n",
    "    def Propagation(self, X, y):\n",
    "        # Forward Propagation\n",
    "        \n",
    "        Z1 = np.dot(X , self.W1) + self.b1\n",
    "        A1 = self.TangH(Z1)\n",
    "        Z2 = np.dot(A1, self.W2) + self.b2\n",
    "        A2 = self.TangH(Z2)\n",
    "        Z3 = np.dot(A2, self.W3) + self.b3\n",
    "        A3 = self.sigmoid(Z3)\n",
    "        cost   = self.getCost(y, A3)        \n",
    "        d_cost = self.deltaCost(y, A3)\n",
    "        \n",
    "        # Backward Propagation\n",
    "        \n",
    "        dW3     = np.dot(A2.T, d_cost)\n",
    "        db3     = np.sum(d_cost, axis=0, keepdims=True) \n",
    "        \n",
    "        # Hidden Layer 2\n",
    "        dhidden2 = np.dot(d_cost, self.W3.T)\n",
    "        \n",
    "        # The TangH derivative\n",
    "        dG2 = self.deltaTangH(Z2)\n",
    "        #dhidden[A1 <= 0] = 0\n",
    "        assert(dG2.shape == dhidden2.shape)\n",
    "        dhidden2 = dG2 * dhidden2\n",
    "        # Second Layer\n",
    "        dW2  = np.matmul(A1.T, dhidden2)\n",
    "        db2  = np.sum(dhidden2, axis=0, keepdims=True)        \n",
    "    \n",
    "        # Hidden Layer 3\n",
    "        dhidden1 = np.dot(dhidden2, self.W2.T)\n",
    "        \n",
    "        # The TangH derivative\n",
    "        dG1 = self.deltaTangH(Z1)\n",
    "        #dhidden[A1 <= 0] = 0\n",
    "        assert(dG1.shape == dhidden1.shape)\n",
    "        dhidden1 = dG1 * dhidden1\n",
    "        # First Layer\n",
    "        dW1  = np.matmul(X.T, dhidden1)\n",
    "        db1  = np.sum(dhidden1, axis=0, keepdims=True)  \n",
    "        \n",
    "        # Regularization L2\n",
    "        dW1 += self.l2_coef * self.W1\n",
    "        dW2 += self.l2_coef * self.W2\n",
    "        dW3 += self.l2_coef * self.W3\n",
    "\n",
    "        # Regularization L1\n",
    "        dW1 += self.l1_coef * np.multiply(self.W1, 1 / np.abs(self.W1))\n",
    "        dW2 += self.l1_coef * np.multiply(self.W2, 1 / np.abs(self.W2))\n",
    "        dW3 += self.l1_coef * np.multiply(self.W3, 1 / np.abs(self.W3))  \n",
    "        \n",
    "        assert(dW1.shape == self.W1.shape)\n",
    "        assert(db1.dtype == float)\n",
    "        assert(dW2.shape == self.W2.shape)\n",
    "        assert(db2.dtype == float)\n",
    "        assert(dW3.shape == self.W3.shape)\n",
    "        assert(db3.dtype == float)\n",
    "        \n",
    "        grads = { \n",
    "                 \"dW1\" : dW1,\n",
    "                 \"db1\" : db1,\n",
    "                 \"dW2\" : dW2,\n",
    "                 \"db2\" : db2,   \n",
    "                 \"dW3\" : dW3,\n",
    "                 \"db3\" : db3   \n",
    "        }\n",
    "        \n",
    "        return grads, cost\n",
    "    \n",
    "    def train(self, X, y):\n",
    "        \"\"\"\n",
    "            function to minimize the Cost\n",
    "            \n",
    "            Args:\n",
    "                X: Matrix of features vectors for each review\n",
    "                y: Labels of each Matrix\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        grads, cost = self.Propagation(X, y)\n",
    "        \n",
    "        dW1 = grads[\"dW1\"]\n",
    "        db1 = grads[\"db1\"]\n",
    "        dW2 = grads[\"dW2\"]\n",
    "        db2 = grads[\"db2\"]        \n",
    "        dW3 = grads[\"dW3\"]\n",
    "        db3 = grads[\"db3\"]\n",
    "        \n",
    "        self.W1 = self.W1 - dW1 * self.lr\n",
    "        self.b1 = self.b1 - db1 * self.lr\n",
    "        self.W2 = self.W2 - dW2 * self.lr\n",
    "        self.b2 = self.b2 - db2 * self.lr\n",
    "        self.W3 = self.W3 - dW3 * self.lr\n",
    "        self.b3 = self.b3 - db3 * self.lr        \n",
    "        \n",
    "        return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X, y, batch1, batch2, iterations, stepplot, crossval):\n",
    "    \n",
    "    split = int(X.shape[0]*crossval)\n",
    "\n",
    "    X_data_train = X[:split]\n",
    "    y_data_train = y[:split]\n",
    "\n",
    "    X_data_valid = X[split:]\n",
    "    y_data_valid = y[split:]\n",
    "\n",
    "    fmt    = '\\n\\n{:3d} epoch: {:3.2f} ep/min, loss_train = {:5.4f}, loss_val = {:5.4f}, acc_train = {:4.3f}, acc_val = {:4.3f}'\n",
    "\n",
    "\n",
    "    train_epoch     = []\n",
    "    valid_epoch     = []\n",
    "    acc_train_epoch = []\n",
    "    acc_valid_epoch = []\n",
    "    train_elem      = []\n",
    "\n",
    "    for i in range(iterations):\n",
    "        loss_t  = 0.0\n",
    "        n_batch = X_data_train.shape[0]/batch1\n",
    "        st = time.time()\n",
    "\n",
    "        for i_batch in range(0,X_data_train.shape[0], batch1):\n",
    "            X_batch  = X_data_train[i_batch:i_batch + batch1].astype(np.float32)\n",
    "            y_batch  = y_data_train[i_batch:i_batch + batch1]\n",
    "            loss_tmp = net.train(X_batch , y_batch)\n",
    "            loss_t  += loss_tmp\n",
    "            \n",
    "\n",
    "            if i_batch  % stepplot == 0:\n",
    "                train_elem.append(loss_tmp)\n",
    "                print('-> element : [{:5d}], loss_temp = {:5.4f}'.format(i_batch, loss_tmp))\n",
    "\n",
    "        if (i+1)%1 == 0:\n",
    "            train_epoch.append(loss_t/n_batch)\n",
    "            acc_train = 0\n",
    "            t_batch = X_data_train.shape[0]/batch2\n",
    "            for i_batch in range(0,X_data_train.shape[0], batch2):\n",
    "                X_batch_   = X_data_train[i_batch:i_batch + batch2].astype(np.float32)\n",
    "                y_batch_   = y_data_train[i_batch:i_batch + batch2]\n",
    "                acc_train += net.acc(X_batch_, y_batch_)\n",
    "\n",
    "            acc_train_epoch.append(acc_train/t_batch)\n",
    "            loss_valid = 0\n",
    "            acc_valid  = 0\n",
    "\n",
    "            v_batch = X_data_valid.shape[0]/batch2\n",
    "            for i_batch in range(0,X_data_valid.shape[0], batch2):\n",
    "                X_batch_v = X_data_valid[i_batch:i_batch + batch2].astype(np.float32)\n",
    "                y_batch_v = y_data_valid[i_batch:i_batch + batch2]\n",
    "\n",
    "                y_hat_batch_v = net.pred(X_batch_v)\n",
    "                loss_valid   += net.getCost(y_batch_v, y_hat_batch_v)\n",
    "\n",
    "                #X_batch_t = X_data_test[i_batch:i_batch + batch2]\n",
    "                #y_batch_t = y_data_test[i_batch:i_batch + batch2]\n",
    "\n",
    "                acc_valid+= net.acc(X_batch_v, y_batch_v)\n",
    "            valid_epoch.append(loss_valid/v_batch)\n",
    "            acc_valid_epoch.append(acc_valid/v_batch)\n",
    "            dt   = time.time() - st\n",
    "            print(fmt.format((i+1), 60/dt,\n",
    "                                    loss_t    /n_batch, \n",
    "                                    loss_valid/v_batch,\n",
    "                                    acc_train /n_batch,\n",
    "                                    acc_valid /v_batch))\n",
    "    \n",
    "    history = {\n",
    "                \"loss_temp\" : train_elem,\n",
    "                \"loss_epoch\": train_epoch,\n",
    "                \"loss_valid\": valid_epoch,\n",
    "                \"acc_train\" : acc_train_epoch,\n",
    "                \"acc_valid\" : acc_valid_epoch\n",
    "                }\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, m = X_train.shape\n",
    "net  = Multilayer(input_size=m, hid_units1=10, hid_units2=3, lr=1e-3, lambda_1=1e-6, lambda_2=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> element : [    0], loss_temp = 0.4207\n",
      "-> element : [  500], loss_temp = 0.1997\n",
      "-> element : [ 1000], loss_temp = 0.4144\n",
      "-> element : [ 1500], loss_temp = 0.5233\n",
      "-> element : [ 2000], loss_temp = 0.5061\n",
      "-> element : [ 2500], loss_temp = 0.2399\n",
      "-> element : [ 3000], loss_temp = 0.2990\n",
      "-> element : [ 3500], loss_temp = 0.6698\n",
      "-> element : [ 4000], loss_temp = 0.6432\n",
      "-> element : [ 4500], loss_temp = 0.4117\n",
      "-> element : [ 5000], loss_temp = 0.1776\n",
      "-> element : [ 5500], loss_temp = 0.1652\n",
      "-> element : [ 6000], loss_temp = 0.3432\n",
      "-> element : [ 6500], loss_temp = 0.4386\n",
      "-> element : [ 7000], loss_temp = 0.7232\n",
      "-> element : [ 7500], loss_temp = 0.5498\n",
      "-> element : [ 8000], loss_temp = 0.3577\n",
      "-> element : [ 8500], loss_temp = 0.4301\n",
      "-> element : [ 9000], loss_temp = 0.1858\n",
      "-> element : [ 9500], loss_temp = 0.1390\n",
      "-> element : [10000], loss_temp = 0.3200\n",
      "-> element : [10500], loss_temp = 0.2950\n",
      "-> element : [11000], loss_temp = 0.1483\n",
      "-> element : [11500], loss_temp = 0.1605\n",
      "-> element : [12000], loss_temp = 0.1290\n",
      "-> element : [12500], loss_temp = 0.1987\n",
      "-> element : [13000], loss_temp = 0.1304\n",
      "-> element : [13500], loss_temp = 0.1423\n",
      "-> element : [14000], loss_temp = 0.2103\n",
      "-> element : [14500], loss_temp = 0.7162\n",
      "-> element : [15000], loss_temp = 0.9161\n",
      "-> element : [15500], loss_temp = 0.1350\n",
      "-> element : [16000], loss_temp = 0.1478\n",
      "-> element : [16500], loss_temp = 0.1027\n",
      "-> element : [17000], loss_temp = 0.3600\n",
      "-> element : [17500], loss_temp = 0.4828\n",
      "-> element : [18000], loss_temp = 0.1184\n",
      "-> element : [18500], loss_temp = 0.1101\n",
      "-> element : [19000], loss_temp = 0.0979\n",
      "-> element : [19500], loss_temp = 0.2591\n",
      "-> element : [20000], loss_temp = 1.0842\n",
      "-> element : [20500], loss_temp = 0.9121\n",
      "-> element : [21000], loss_temp = 0.4764\n",
      "-> element : [21500], loss_temp = 0.1009\n",
      "-> element : [22000], loss_temp = 0.1730\n",
      "-> element : [22500], loss_temp = 0.3317\n",
      "-> element : [23000], loss_temp = 0.0980\n",
      "-> element : [23500], loss_temp = 0.1276\n",
      "-> element : [24000], loss_temp = 0.4055\n",
      "-> element : [24500], loss_temp = 0.3239\n",
      "-> element : [25000], loss_temp = 0.4907\n",
      "-> element : [25500], loss_temp = 0.0922\n",
      "-> element : [26000], loss_temp = 0.1005\n",
      "-> element : [26500], loss_temp = 0.5041\n",
      "-> element : [27000], loss_temp = 0.1139\n",
      "-> element : [27500], loss_temp = 0.2122\n",
      "-> element : [28000], loss_temp = 0.1567\n",
      "-> element : [28500], loss_temp = 0.2172\n",
      "-> element : [29000], loss_temp = 0.1783\n",
      "-> element : [29500], loss_temp = 0.1387\n",
      "-> element : [30000], loss_temp = 0.3391\n",
      "-> element : [30500], loss_temp = 0.4115\n",
      "-> element : [31000], loss_temp = 0.5378\n",
      "-> element : [31500], loss_temp = 0.6815\n",
      "-> element : [32000], loss_temp = 0.1064\n",
      "-> element : [32500], loss_temp = 0.1155\n",
      "-> element : [33000], loss_temp = 0.0874\n",
      "-> element : [33500], loss_temp = 0.0873\n",
      "-> element : [34000], loss_temp = 0.0940\n",
      "-> element : [34500], loss_temp = 0.0945\n",
      "\n",
      "\n",
      "  1 epoch: 0.05 ep/min, loss_train = 0.3048, loss_val = 0.2970, acc_train = 0.008, acc_val = 0.741\n"
     ]
    }
   ],
   "source": [
    "its   = 1\n",
    "btch1 = 1\n",
    "step  = 500\n",
    "history = train_model(X=X_train, y=y_train, batch1=btch1, batch2=100, iterations=its,stepplot=step, crossval=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "btch1 = 1\n",
    "loss_t = history['loss_temp']\n",
    "\n",
    "it     = [i*step for i in range(len(loss_t))]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "lt      = ax.plot(it, loss_t)\n",
    "ax.set(xlabel='Review Number', ylabel='Cost', title='Cost on each review')\n",
    "ax.axis([0, len(loss_t)*step  + 0.5, 0.0, 5.0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  0.3047788921387269\n",
      "valid loss:  0.29700210003381766\n"
     ]
    }
   ],
   "source": [
    "train_epoch = history['loss_epoch']\n",
    "valid_epoch = history['loss_valid']\n",
    "\n",
    "print('train loss: ', train_epoch[-1])\n",
    "print('valid loss: ', valid_epoch[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy:  0.8099428571428575\n",
      "valid accuracy:  0.7409333333333333\n"
     ]
    }
   ],
   "source": [
    "acc_train_epoch = history['acc_train']\n",
    "acc_valid_epoch = history['acc_valid']\n",
    "\n",
    "print('train accuracy: ', acc_train_epoch[-1])\n",
    "print('valid accuracy: ', acc_valid_epoch[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This lines are for plot error on each epoch\n",
    "\n",
    "#ep = np.arange(1, its + 1, 1)\n",
    "\n",
    "#train_epoch = history['loss_epoch']\n",
    "#valid_epoch = history['loss_valid']\n",
    "#fig, ax = plt.subplots(figsize=(14, 8))\n",
    "#l1 , l2   = ax.plot(ep, train_epoch, ep, valid_epoch)\n",
    "#ax.set(xlabel='Epoch', ylabel='Cost', title='Logistic Regression with L1 and L2 regularization')\n",
    "#ax.axis([0.8, its + 0.5, 0.1, 0.8])\n",
    "#plt.legend([l1, l2],[\"Training\",\"Validation\"])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This lines are for plot accuracy on each epoch\n",
    "\n",
    "#fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "#acc_train_epoch = history['acc_train']\n",
    "#acc_test_epoch  = history['acc_test']\n",
    "\n",
    "#l3, l4  = ax.plot(ep, acc_train_epoch, ep, acc_test_epoch)\n",
    "#ax.set(xlabel='Epoch', ylabel='Accuracy', title='Multiple Layer Perceptron')\n",
    "#ax.axis([0.8, its + 0.5, 0.68, 0.88])\n",
    "#plt.legend([l3, l4],[\"Train Accuracy\", \"Test Accuracy\"])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous section, we successfully trained a model to predict the sentiment of a movie review. Unfortunately, if we'd close this IPython notebook at this point, we'd have to go through the whole learning process again and again if we'd want to make a prediction on \"new data.\"\n",
    "\n",
    "So, to reuse this model, we could use the [`pickle`](https://docs.python.org/3.5/library/pickle.html) module to \"serialize a Python object structure\". Or even better, we could use the [`joblib`](https://pypi.python.org/pypi/joblib) library, which handles large NumPy arrays more efficiently.\n",
    "\n",
    "To install:\n",
    "conda install -c anaconda joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./net.pkl']"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Exercise 3: compare  with your Neural Network\n",
    "\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "joblib.dump(vectorizer, './vectorizer.pkl')\n",
    "joblib.dump(net,'./net.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us restart this IPython notebook and check if the we can load our serialized objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = joblib.load('./vectorizer.pkl')\n",
    "net        = joblib.load('./net.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading the `tokenizer`, `HashingVectorizer`, and the tranined logistic regression model, we can use it to make predictions on new data, which can be useful, for example, if we'd want to embed our classifier into a web application -- a topic for another IPython notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True : Good comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "False: Bad comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "100.00%\r",
      "Done     \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ True]])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = ['I loved this movie']\n",
    "m  = tokenizer(example[0])\n",
    "X = vectorizer.transform([m])\n",
    "net.predSentiment(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "100.00%\r",
      "Done     \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ True]])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = ['This movie was great!']\n",
    "m  = tokenizer(example[0])\n",
    "X = vectorizer.transform([m])\n",
    "net.predSentiment(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "100.00%\r",
      "Done     \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[False]])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = [\"I didn't like this movie\"]\n",
    "m  = tokenizer(example[0])\n",
    "X = vectorizer.transform([m])\n",
    "\n",
    "net.predSentiment(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "100.00%\r",
      "Done     \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[False]])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = ['I did not like this movie']\n",
    "m  = tokenizer(example[0])\n",
    "X = vectorizer.transform([m])\n",
    "net.predSentiment(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "100.00%\r",
      "Done     \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[False]])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = [\"I don't like this movie\"]\n",
    "m  = tokenizer(example[0])\n",
    "X = vectorizer.transform([m])\n",
    "net.predSentiment(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In complex sentences the result is not the correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "100.00%\r",
      "Done     \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ True]])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = [\"I love the actor but the history was the worst, I don't recommend this one\"]\n",
    "m  = tokenizer(example[0])\n",
    "X = vectorizer.transform([m])\n",
    "net.predSentiment(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
