{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression for Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapted from http://nbviewer.jupyter.org/github/rasbt/pattern_classification/blob/master/machine_learning/scikit-learn/outofcore_modelpersistence.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The IMDb Movie Review Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will train a simple logistic regression model to classify movie reviews from the 50k IMDb review dataset that has been collected by Maas et. al.\n",
    "\n",
    "> AL Maas, RE Daly, PT Pham, D Huang, AY Ng, and C Potts. Learning word vectors for sentiment analysis. In Proceedings of the 49th Annual Meeting of the Association for Computational Lin- guistics: Human Language Technologies, pages 142â€“150, Portland, Oregon, USA, June 2011. Association for Computational Linguistics\n",
    "\n",
    "[Source: http://ai.stanford.edu/~amaas/data/sentiment/]\n",
    "\n",
    "The dataset consists of 50,000 movie reviews from the original \"train\" and \"test\" subdirectories. The class labels are binary (1=positive and 0=negative) and contain 25,000 positive and 25,000 negative movie reviews, respectively.\n",
    "For simplicity, I assembled the reviews in a single CSV file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import collections\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>OK, lets start with the best. the building. al...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>The British 'heritage film' industry is out of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I don't even know where to begin on this one. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>Richard Tyler is a little boy who is scared of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>I waited long to watch this movie. Also becaus...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment\n",
       "49995  OK, lets start with the best. the building. al...          0\n",
       "49996  The British 'heritage film' industry is out of...          0\n",
       "49997  I don't even know where to begin on this one. ...          0\n",
       "49998  Richard Tyler is a little boy who is scared of...          0\n",
       "49999  I waited long to watch this movie. Also becaus...          1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if you want to download the original file:\n",
    "#df = pd.read_csv('https://raw.githubusercontent.com/rasbt/pattern_classification/master/data/50k_imdb_movie_reviews.csv')\n",
    "# otherwise load local file\n",
    "df = pd.read_csv('shuffled_movie_data.csv')\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us shuffle the class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['In 1974, the teenager Martha Moxley (Maggie Grace) moves to the high-class area of Belle Haven, Greenwich, Connecticut. On the Mischief Night, eve of Halloween, she was murdered in the backyard of her house and her murder remained unsolved. Twenty-two years later, the writer Mark Fuhrman (Christopher Meloni), who is a former LA detective that has fallen in disgrace for perjury in O.J. Simpson trial and moved to Idaho, decides to investigate the case with his partner Stephen Weeks (Andrew Mitchell) with the purpose of writing a book. The locals squirm and do not welcome them, but with the support of the retired detective Steve Carroll (Robert Forster) that was in charge of the investigation in the 70\\'s, they discover the criminal and a net of power and money to cover the murder.<br /><br />\"Murder in Greenwich\" is a good TV movie, with the true story of a murder of a fifteen years old girl that was committed by a wealthy teenager whose mother was a Kennedy. The powerful and rich family used their influence to cover the murder for more than twenty years. However, a snoopy detective and convicted perjurer in disgrace was able to disclose how the hideous crime was committed. The screenplay shows the investigation of Mark and the last days of Martha in parallel, but there is a lack of the emotion in the dramatization. My vote is seven.<br /><br />Title (Brazil): Not Available',\n",
       "       1], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head().values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## uncomment these lines if you have dowloaded the original file:\n",
    "#np.random.seed(0)\n",
    "#df = df.reindex(np.random.permutation(df.index))\n",
    "#df[['review', 'sentiment']].to_csv('shuffled_movie_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us define a simple `tokenizer` that splits the text into individual word tokens. Furthermore, we will use some simple regular expression to remove HTML markup and all non-letter characters but \"emoticons,\" convert the text to lower case, remove stopwords, and apply the Porter stemming algorithm to convert the words into their root form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def tokenizer(text):\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text.lower())\n",
    "    text = re.sub('[\\W]+', ' ', text.lower())\n",
    "    text = [w for w in text.split()]\n",
    "    tokenized = [wordnet_lemmatizer.lemmatize(w) for w in text]\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's give it at try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this', 'is', 'a', 'test']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('This :) is a <a> test! :-)</br>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define a generator that returns the document body and the corresponding class label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_docs(path):\n",
    "    with open(path, 'r') as csv:\n",
    "        next(csv) # skip header\n",
    "        for line in csv:\n",
    "            text, label = line[:-3], int(line[-2])\n",
    "            yield text, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To conform that the `stream_docs` function fetches the documents as intended, let us execute the following code snippet before we implement the `get_minibatch` function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we confirmed that our `stream_docs` functions works, we will now implement a `get_minibatch` function to fetch a specified number (`size`) of documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_minibatch(doc_stream, size):\n",
    "    docs, y = [], []\n",
    "    for _ in range(size):\n",
    "        text, label = next(doc_stream)\n",
    "        docs.append(text)\n",
    "        y.append(label)\n",
    "    return docs, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will make use of the \"hashing trick\" through scikit-learns [HashingVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.HashingVectorizer.html) to create a bag-of-words model of our documents. Details of the bag-of-words model for document classification can be found at  [Naive Bayes and Text Classification I - Introduction and Theory](http://arxiv.org/abs/1410.5329)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: define features based on word embeddings (pre-trained word2vec / Glove/Fastext emebddings can be used)\n",
    "# Define suitable d dimension, and sequence length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train our own embedding vectors with all the reviews, with a 40 size of each vector to save memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_generator = stream_docs(path='shuffled_movie_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done     \n",
      "\n",
      "50000\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "doc_generator = stream_docs(path='shuffled_movie_data.csv')\n",
    "\n",
    "sentences = []\n",
    "labels    = []\n",
    "lengths   = []\n",
    "for idx, review in enumerate(doc_generator):\n",
    "    toVec = tokenizer(review[0])\n",
    "    sentences.append(toVec)\n",
    "    labels.append(review[1])\n",
    "    lengths.append(len(toVec))\n",
    "    sys.stdout.write('\\r{:5.2f}%'.format(100*(idx+1)/50000))\n",
    "sys.stdout.write('\\rDone     \\n\\n')  \n",
    "print(len(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting embedding vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained!\n"
     ]
    }
   ],
   "source": [
    "emb_size = 40\n",
    "\n",
    "model = Word2Vec(sentences, size=emb_size, window=5, min_count=5, workers=4)\n",
    "print('trained!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'woman' is similar to 'girl' with a score of 0.8877\n"
     ]
    }
   ],
   "source": [
    "sim = model.wv.most_similar(positive=['woman'], topn=1)\n",
    "print(\"'woman' is similar to '{}' with a score of {:1.4f}\".format(sim[0][0],sim[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary size : 35327\n"
     ]
    }
   ],
   "source": [
    "print('vocabulary size :', len(model.wv.vocab.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding size :  (40,)\n"
     ]
    }
   ],
   "source": [
    "print('embedding size : ', model.wv['woman'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewVectorizer:\n",
    "    def __init__(self, model, maxlen):\n",
    "        self.model  = model\n",
    "        self.maxlen = maxlen\n",
    "    def transform(self, reviews_tokenized):\n",
    "        n = len(reviews_tokenized)\n",
    "        vector = np.zeros((n, self.maxlen, emb_size), dtype=np.float16)\n",
    "        for idx, review in enumerate(reviews_tokenized):\n",
    "            for iw, word in enumerate(review):\n",
    "                if word in self.model.wv.vocab:\n",
    "                    vector[idx][iw] = self.model.wv[word]\n",
    "            sys.stdout.write('\\r{:5.2f}%'.format(100*(idx+1)/n))\n",
    "        sys.stdout.write('\\rDone     \\n\\n')                    \n",
    "        vector = vector.reshape((n, -1))\n",
    "        return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAXLEN = max(lengths)\n",
    "vectorizer = ReviewVectorizer(model, MAXLEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done     \n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = vectorizer.transform(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (MAXLEN*emb_size == res.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (50000, 99920)\n",
      "y_train shape:  (50000, 1)\n"
     ]
    }
   ],
   "source": [
    "y_train = np.asarray(labels).reshape((-1, 1))\n",
    "X_train = res\n",
    "del res\n",
    "print('X_train shape: ',X_train.shape)\n",
    "print('y_train shape: ',y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Define at least a Three layer neural network. Define its structure (number of hidden neurons, etc)\n",
    "# Define a nonlinear function for hidden layers.\n",
    "# Define a suitable loss function for binary classification\n",
    "# Implement the backpropagation algorithm for this structure\n",
    "# Do not use Keras / Tensorflow /PyTorch etc. libraries\n",
    "# Train the model using SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using 3 layers, 2 hidden layers with tangent hiperbolic activation and a sigmoid function at the end. This neural network also work with L1 and L2 regularization.\n",
    "\n",
    "We try to use few neurons on hidden layers to get a better generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Multilayer:\n",
    "    \"\"\"\n",
    "        Logistic Regression with L1 and L2 regularization\n",
    "        \n",
    "        Arguments:\n",
    "                \n",
    "                alpha   : Learning Rate\n",
    "                l1_coef : Lambda 1\n",
    "                l2_coef : Lambda 2\n",
    "            \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__ (self, input_size, hid_units1, hid_units2, lr, lambda_1, lambda_2):\n",
    "        self.W1      = np.random.randn(input_size, hid_units1) * np.sqrt(1/input_size)\n",
    "        self.b1      = np.zeros((1, hid_units1))\n",
    "        self.W2      = np.random.randn(hid_units1, hid_units2) * np.sqrt(1/hid_units1)\n",
    "        self.b2      = np.zeros((1, hid_units2))\n",
    "        self.W3      = np.random.randn(hid_units2,          1) * np.sqrt(1/hid_units2)\n",
    "        self.b3      = 0.0\n",
    "        self.lr      = lr\n",
    "        self.l1_coef = lambda_1\n",
    "        self.l2_coef = lambda_2\n",
    "        \n",
    "    def ReLU(self, z):\n",
    "        return np.maximum(0, z)\n",
    "    \n",
    "    def TangH(self, z):\n",
    "        return (np.exp(z) - np.exp(-z))/(np.exp(z) + np.exp(-z) + 1e-8)\n",
    "    \n",
    "    def deltaTangH(self, z):\n",
    "        return 4 * np.exp(z) * np.exp(-z)/(np.exp(z) + np.exp(-z)+ 1e-8)**2\n",
    "    \n",
    "    def sigmoid(self,z):\n",
    "        \"\"\"\n",
    "            Activation function\n",
    "            \n",
    "            Arguments:  \n",
    "                z : W*X + b\n",
    "                \n",
    "            Returns:\n",
    "                sigmoid function of z.\n",
    "                \n",
    "        \"\"\"\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    def deltaCost(self, y, y_hat):\n",
    "        return y_hat - y\n",
    "        \n",
    "    def pred(self, X):\n",
    "        \"\"\"\n",
    "            Given a X matrix as a input we return the prediction for\n",
    "            W and b.\n",
    "            \n",
    "            Args:\n",
    "                X : Matrix of features vectors for each review\n",
    "            \n",
    "            Returns:\n",
    "                Prediction without a threshold\n",
    "        \"\"\"\n",
    "        Z1 = np.dot(X , self.W1) + self.b1\n",
    "        A1 = self.TangH(Z1)\n",
    "        Z2 = np.dot(A1, self.W2) + self.b2\n",
    "        A2 = self.TangH(Z2)   \n",
    "        Z3 = np.dot(A2, self.W3) + self.b3\n",
    "        A3 = self.sigmoid(Z3)          \n",
    "        return A3\n",
    "\n",
    "    def predSentiment(self, X):\n",
    "        \"\"\"\n",
    "            Given a X matrix as a input we return the prediction with threshold \n",
    "            for W and b.\n",
    "            \n",
    "            Args:\n",
    "                X : Matrix of features vectors for each review\n",
    "            \n",
    "            Returns:\n",
    "                Prediction with threshold\n",
    "        \"\"\"\n",
    "        return self.pred(X) > 0.5\n",
    "    \n",
    "    def acc(self, X, y):\n",
    "        \"\"\"\n",
    "            Accuracy of a input and label\n",
    "            \n",
    "            Args:\n",
    "                X: Matrix of features vectors for each review\n",
    "                y: Labels of each Matrix\n",
    "            \n",
    "            Returns:\n",
    "                A number between 0 and 1.0\n",
    "        \"\"\"\n",
    "        \n",
    "        return np.mean(self.predSentiment(X) == y)\n",
    "    \n",
    "    def getCost(self,y, y_hat):\n",
    "        \"\"\"\n",
    "            Cost function\n",
    "            \n",
    "                Cost = - [y * log(sigma(W*X + b)) + (1 - y) * log(1 - sigma(W*X + b))] \n",
    "                         + 0.5 * l2_ratio * ||w||^2_2 \n",
    "                         + l1_ratio * ||w||_1 \n",
    "            \n",
    "            Args:\n",
    "                X: Matrix of features vectors for each review\n",
    "                y: Labels of each Matrix\n",
    "                \n",
    "            Returns:\n",
    "                Cost using L1 and L2 regularizations \n",
    "                \n",
    "        \"\"\"\n",
    "        y_hat = np.clip(y_hat, 1e-8, 1 - 1e-8)\n",
    "        cost  = - 0.5 * np.mean(np.multiply(y  , np.log(y_hat     + 1e-5))\n",
    "                             + np.multiply(1-y , np.log(1 - y_hat + 1e-5)))\n",
    "        \n",
    "        cost += 0.5 * self.l2_coef * np.sum(np.square(self.W1)) + self.l1_coef * np.sum(np.abs(self.W1)) \n",
    "        cost += 0.5 * self.l2_coef * np.sum(np.square(self.W2)) + self.l1_coef * np.sum(np.abs(self.W2))\n",
    "        \n",
    "        return cost \n",
    "    \n",
    "    def Propagation(self, X, y):\n",
    "        # Forward Propagation\n",
    "        \n",
    "        Z1 = np.dot(X , self.W1) + self.b1\n",
    "        A1 = self.TangH(Z1)\n",
    "        Z2 = np.dot(A1, self.W2) + self.b2\n",
    "        A2 = self.TangH(Z2)\n",
    "        Z3 = np.dot(A2, self.W3) + self.b3\n",
    "        A3 = self.sigmoid(Z3)\n",
    "        cost   = self.getCost(y, A3)        \n",
    "        d_cost = self.deltaCost(y, A3)\n",
    "        \n",
    "        # Backward Propagation\n",
    "        \n",
    "        dW3     = np.dot(A2.T, d_cost)\n",
    "        db3     = np.sum(d_cost, axis=0, keepdims=True) \n",
    "        \n",
    "        # Hidden Layer 2\n",
    "        dhidden2 = np.dot(d_cost, self.W3.T)\n",
    "        \n",
    "        # The TangH derivative\n",
    "        dG2 = self.deltaTangH(Z2)\n",
    "        #dhidden[A1 <= 0] = 0\n",
    "        assert(dG2.shape == dhidden2.shape)\n",
    "        dhidden2 = dG2 * dhidden2\n",
    "        # Second Layer\n",
    "        dW2  = np.matmul(A1.T, dhidden2)\n",
    "        db2  = np.sum(dhidden2, axis=0, keepdims=True)        \n",
    "    \n",
    "        # Hidden Layer 3\n",
    "        dhidden1 = np.dot(dhidden2, self.W2.T)\n",
    "        \n",
    "        # The TangH derivative\n",
    "        dG1 = self.deltaTangH(Z1)\n",
    "        #dhidden[A1 <= 0] = 0\n",
    "        assert(dG1.shape == dhidden1.shape)\n",
    "        dhidden1 = dG1 * dhidden1\n",
    "        # First Layer\n",
    "        dW1  = np.matmul(X.T, dhidden1)\n",
    "        db1  = np.sum(dhidden1, axis=0, keepdims=True)  \n",
    "        \n",
    "        # Regularization L2\n",
    "        dW1 += self.l2_coef * self.W1\n",
    "        dW2 += self.l2_coef * self.W2\n",
    "        dW3 += self.l2_coef * self.W3\n",
    "\n",
    "        # Regularization L1\n",
    "        dW1 += self.l1_coef * np.multiply(self.W1, 1 / np.abs(self.W1))\n",
    "        dW2 += self.l1_coef * np.multiply(self.W2, 1 / np.abs(self.W2))\n",
    "        dW3 += self.l1_coef * np.multiply(self.W3, 1 / np.abs(self.W3))  \n",
    "        \n",
    "        assert(dW1.shape == self.W1.shape)\n",
    "        assert(db1.dtype == float)\n",
    "        assert(dW2.shape == self.W2.shape)\n",
    "        assert(db2.dtype == float)\n",
    "        assert(dW3.shape == self.W3.shape)\n",
    "        assert(db3.dtype == float)\n",
    "        \n",
    "        grads = { \n",
    "                 \"dW1\" : dW1,\n",
    "                 \"db1\" : db1,\n",
    "                 \"dW2\" : dW2,\n",
    "                 \"db2\" : db2,   \n",
    "                 \"dW3\" : dW3,\n",
    "                 \"db3\" : db3   \n",
    "        }\n",
    "        \n",
    "        return grads, cost\n",
    "    \n",
    "    def train(self, X, y):\n",
    "        \"\"\"\n",
    "            function to minimize the Cost\n",
    "            \n",
    "            Args:\n",
    "                X: Matrix of features vectors for each review\n",
    "                y: Labels of each Matrix\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        grads, cost = self.Propagation(X, y)\n",
    "        \n",
    "        dW1 = grads[\"dW1\"]\n",
    "        db1 = grads[\"db1\"]\n",
    "        dW2 = grads[\"dW2\"]\n",
    "        db2 = grads[\"db2\"]        \n",
    "        dW3 = grads[\"dW3\"]\n",
    "        db3 = grads[\"db3\"]\n",
    "        \n",
    "        self.W1 = self.W1 - dW1 * self.lr\n",
    "        self.b1 = self.b1 - db1 * self.lr\n",
    "        self.W2 = self.W2 - dW2 * self.lr\n",
    "        self.b2 = self.b2 - db2 * self.lr\n",
    "        self.W3 = self.W3 - dW3 * self.lr\n",
    "        self.b3 = self.b3 - db3 * self.lr        \n",
    "        \n",
    "        return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X, y, batch1, batch2, iterations, stepplot, crossval):\n",
    "    \n",
    "    split = int(X.shape[0]*crossval)\n",
    "\n",
    "    X_data_train = X[:split]\n",
    "    y_data_train = y[:split]\n",
    "\n",
    "    X_data_valid = X[split:]\n",
    "    y_data_valid = y[split:]\n",
    "\n",
    "    fmt    = '\\n\\n{:3d} epoch: {:3.2f} ep/min, loss_train = {:5.4f}, loss_val = {:5.4f}, acc_train = {:4.3f}, acc_val = {:4.3f}'\n",
    "\n",
    "\n",
    "    train_epoch     = []\n",
    "    valid_epoch     = []\n",
    "    acc_train_epoch = []\n",
    "    acc_valid_epoch = []\n",
    "    train_elem      = []\n",
    "\n",
    "    for i in range(iterations):\n",
    "        loss_t  = 0.0\n",
    "        n_batch = X_data_train.shape[0]/batch1\n",
    "        st = time.time()\n",
    "\n",
    "        for i_batch in range(0,X_data_train.shape[0], batch1):\n",
    "            X_batch  = X_data_train[i_batch:i_batch + batch1].astype(np.float32)\n",
    "            y_batch  = y_data_train[i_batch:i_batch + batch1]\n",
    "            loss_tmp = net.train(X_batch , y_batch)\n",
    "            loss_t  += loss_tmp\n",
    "            \n",
    "\n",
    "            if i_batch  % stepplot == 0:\n",
    "                train_elem.append(loss_tmp)\n",
    "                print('-> element : [{:5d}], loss_temp = {:5.4f}'.format(i_batch, loss_tmp))\n",
    "\n",
    "        if (i+1)%1 == 0:\n",
    "            train_epoch.append(loss_t/n_batch)\n",
    "            acc_train = 0\n",
    "            t_batch = X_data_train.shape[0]/batch2\n",
    "            for i_batch in range(0,X_data_train.shape[0], batch2):\n",
    "                X_batch_   = X_data_train[i_batch:i_batch + batch2].astype(np.float32)\n",
    "                y_batch_   = y_data_train[i_batch:i_batch + batch2]\n",
    "                acc_train += net.acc(X_batch_, y_batch_)\n",
    "\n",
    "            acc_train_epoch.append(acc_train/t_batch)\n",
    "            loss_valid = 0\n",
    "            acc_valid  = 0\n",
    "\n",
    "            v_batch = X_data_valid.shape[0]/batch2\n",
    "            for i_batch in range(0,X_data_valid.shape[0], batch2):\n",
    "                X_batch_v = X_data_valid[i_batch:i_batch + batch2].astype(np.float32)\n",
    "                y_batch_v = y_data_valid[i_batch:i_batch + batch2]\n",
    "\n",
    "                y_hat_batch_v = net.pred(X_batch_v)\n",
    "                loss_valid   += net.getCost(y_batch_v, y_hat_batch_v)\n",
    "\n",
    "                #X_batch_t = X_data_test[i_batch:i_batch + batch2]\n",
    "                #y_batch_t = y_data_test[i_batch:i_batch + batch2]\n",
    "\n",
    "                acc_valid+= net.acc(X_batch_v, y_batch_v)\n",
    "            valid_epoch.append(loss_valid/v_batch)\n",
    "            acc_valid_epoch.append(acc_valid/v_batch)\n",
    "            dt   = time.time() - st\n",
    "            print(fmt.format((i+1), 60/dt,\n",
    "                                    loss_t    /n_batch, \n",
    "                                    loss_valid/v_batch,\n",
    "                                    acc_train /t_batch,\n",
    "                                    acc_valid /v_batch))\n",
    "    \n",
    "    history = {\n",
    "                \"loss_temp\" : train_elem,\n",
    "                \"loss_epoch\": train_epoch,\n",
    "                \"loss_valid\": valid_epoch,\n",
    "                \"acc_train\" : acc_train_epoch,\n",
    "                \"acc_valid\" : acc_valid_epoch\n",
    "                }\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, m = X_train.shape\n",
    "net  = Multilayer(input_size=m, hid_units1=10, hid_units2=3, lr=5e-3, lambda_1=1e-6, lambda_2=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> element : [    0], loss_temp = 0.2391\n",
      "-> element : [  500], loss_temp = 0.3403\n",
      "-> element : [ 1000], loss_temp = 0.2851\n",
      "-> element : [ 1500], loss_temp = 0.3564\n",
      "-> element : [ 2000], loss_temp = 0.3256\n",
      "-> element : [ 2500], loss_temp = 0.4542\n",
      "-> element : [ 3000], loss_temp = 0.4255\n",
      "-> element : [ 3500], loss_temp = 0.6359\n",
      "-> element : [ 4000], loss_temp = 0.2596\n",
      "-> element : [ 4500], loss_temp = 0.1745\n",
      "-> element : [ 5000], loss_temp = 0.2508\n",
      "-> element : [ 5500], loss_temp = 0.1683\n",
      "-> element : [ 6000], loss_temp = 0.5479\n",
      "-> element : [ 6500], loss_temp = 0.2014\n",
      "-> element : [ 7000], loss_temp = 0.4235\n",
      "-> element : [ 7500], loss_temp = 0.4782\n",
      "-> element : [ 8000], loss_temp = 0.6279\n",
      "-> element : [ 8500], loss_temp = 0.3643\n",
      "-> element : [ 9000], loss_temp = 0.4006\n",
      "-> element : [ 9500], loss_temp = 0.1016\n",
      "-> element : [10000], loss_temp = 0.3425\n",
      "-> element : [10500], loss_temp = 0.5994\n",
      "-> element : [11000], loss_temp = 0.2587\n",
      "-> element : [11500], loss_temp = 0.1002\n",
      "-> element : [12000], loss_temp = 0.2774\n",
      "-> element : [12500], loss_temp = 0.1383\n",
      "-> element : [13000], loss_temp = 0.3139\n",
      "-> element : [13500], loss_temp = 0.1000\n",
      "-> element : [14000], loss_temp = 0.1393\n",
      "-> element : [14500], loss_temp = 0.4379\n",
      "-> element : [15000], loss_temp = 0.4838\n",
      "-> element : [15500], loss_temp = 0.1845\n",
      "-> element : [16000], loss_temp = 0.5730\n",
      "-> element : [16500], loss_temp = 0.3742\n",
      "-> element : [17000], loss_temp = 0.1766\n",
      "-> element : [17500], loss_temp = 0.5842\n",
      "-> element : [18000], loss_temp = 0.0994\n",
      "-> element : [18500], loss_temp = 0.1234\n",
      "-> element : [19000], loss_temp = 0.0995\n",
      "-> element : [19500], loss_temp = 0.1759\n",
      "-> element : [20000], loss_temp = 0.9716\n",
      "-> element : [20500], loss_temp = 0.4348\n",
      "-> element : [21000], loss_temp = 0.2643\n",
      "-> element : [21500], loss_temp = 0.1165\n",
      "-> element : [22000], loss_temp = 0.0743\n",
      "-> element : [22500], loss_temp = 0.3533\n",
      "-> element : [23000], loss_temp = 0.1190\n",
      "-> element : [23500], loss_temp = 0.2550\n",
      "-> element : [24000], loss_temp = 0.7178\n",
      "-> element : [24500], loss_temp = 0.7163\n",
      "-> element : [25000], loss_temp = 0.0752\n",
      "-> element : [25500], loss_temp = 0.1138\n",
      "-> element : [26000], loss_temp = 0.2539\n",
      "-> element : [26500], loss_temp = 1.1299\n",
      "-> element : [27000], loss_temp = 0.5899\n",
      "-> element : [27500], loss_temp = 0.2492\n",
      "-> element : [28000], loss_temp = 0.0687\n",
      "-> element : [28500], loss_temp = 0.3861\n",
      "-> element : [29000], loss_temp = 0.2822\n",
      "-> element : [29500], loss_temp = 0.2278\n",
      "-> element : [30000], loss_temp = 0.4415\n",
      "-> element : [30500], loss_temp = 0.2920\n",
      "-> element : [31000], loss_temp = 0.1672\n",
      "-> element : [31500], loss_temp = 0.2612\n",
      "-> element : [32000], loss_temp = 0.2923\n",
      "-> element : [32500], loss_temp = 0.0940\n",
      "-> element : [33000], loss_temp = 0.0743\n",
      "-> element : [33500], loss_temp = 0.1710\n",
      "-> element : [34000], loss_temp = 0.1870\n",
      "-> element : [34500], loss_temp = 0.0955\n",
      "\n",
      "\n",
      "  1 epoch: 0.05 ep/min, loss_train = 0.3138, loss_val = 0.2894, acc_train = 0.739, acc_val = 0.712\n"
     ]
    }
   ],
   "source": [
    "its   = 1\n",
    "btch1 = 1\n",
    "step  = 500\n",
    "history = train_model(X=X_train, y=y_train, batch1=btch1, batch2=100, iterations=its,stepplot=step, crossval=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0YAAAHwCAYAAACCKH9ZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzs3Wd4VNe59vF7jQoqCBUkUSRAAtFMry7gAjiuuMR24hYnTn3PiZ1yUu2TxEmc4uTEcZzqxI5LnMRO4hbbuOEGBDC9iyqQRJNQ76jOej/MDBYgiZE0M9Kw/7/r4rI0s2f2Iyykfe+11rOMtVYAAAAA4GSuvi4AAAAAAPoawQgAAACA4xGMAAAAADgewQgAAACA4xGMAAAAADgewQgAAACA4xGMAABhzxiTZYyxxpjIPjj3SGNMnTEmItTnBgAEDsEIAMKMMeY2Y8wG78V4kTHmDWPM/F6+Z4Ex5tJA1egk1tqD1tqB1tq2vq4FANBzBCMACCPGmK9JeljSTyUNkTRS0h8kXdeXdYU7RnsAAAQjAAgTxphESfdLusta+6K1tt5a22KtfdVa+03vMQOMMQ8bY456/zxsjBngfS7VGLPEGFNljKkwxvzHGOMyxvxVnoD1qncU6ludnP/zxpg872tfMcYMb/ecNcb8lzFmn/f9f2+MMZ28j8sYc48xZr8xptwY8y9jTEq7558zxhQbY6qNMSuMMZPaPRdrjPmlMabQ+/xKY0xsu7e/3Rhz0BhTZoz5Thd/l08ZYx4xxrxujKmXtMD7d/eg9/XHjDF/9L23MWaXMWZxu9dHGmNKjTEzT53GZ4xJNMY87h3NO2KM+bEveHnrnuX9+Hbv6yZ5P/+sMebfndUMAAgughEAhI/zJcVIeqmLY74j6TxJ0yVNkzRX0ne9z31d0mFJafKMNv2vJGutvUPSQUnXeKeE/d+pb2qMWSjpAUkflzRMUqGkf5xy2GJJcyRN9R53eSc1fknS9ZIuljRcUqWk37d7/g1JYyWlS9ok6e/tnntQ0ixJF0hKkfQtSe52z8+XNF7SIkn3GWMmdlKDJN0m6SeSEiStlPQzSePk+bvLkZQh6T7vsc9KurXday+XVGat3dTB+z4lqdX7HjMkXSbpc97nlku6xPvxxZIOSLqo3efLu6gXABBEBCMACB+D5bkYb+3imNsl3W+tLbHWlkr6oaQ7vM+1yBNqRnlHmv5jrbV+nvt2SU9YazdZa5sk3SvpfGNMVrtjfmatrbLWHpT0vjwBoyP/Jek71trD3vf6gaSbfCMu1tonrLW17Z6b5h2FcUn6jKSvWGuPWGvbrLWrvcf5/NBae9xau1XSVnnCYWdettausta6JTVJ+oKk/7HWVlhra+WZrniL99hnJF1rjInzfn6bPGHpJMaYIZKukvRV74heiaRftXuf5fIEIEm6UJ6w6fucYAQAfYhgBADho1xS6hk6rw2XZzTHp9D7mCT9QlKepKXGmAPGmHu6ce6T3tdaW+etJ6PdMcXtPm6QNLCT9xol6SXvlLsqSbsktUkaYoyJMMb8zDvNrkZSgfc1qd4/MZL2d1GnvzVI0qF2H6dJipO0sV1db3ofl7U2z1vnNd5wdK08Yamjry1KUlG79/mTPKNfkif4XGiMGSYpQtK/JM3zBsxESVu6qBcAEEQEIwAIHx/IM7JxfRfHHJXn4txnpPcxeUdhvm6tHS3Phf3XjDGLvMedaeTopPc1xsTLM4J1pFtfgcchSVdaa5Pa/Ymx1h6RZyTmOkmXyhMUsnynlFQmqVHSmB6csyPtv+YyScclTWpXU6K1tn2w8k2nu07STm9Y6uhra5KU2u59BllrJ0knAlaDPNMJV1hra+QJc1+QtNI7egUA6AMEIwAIE9baannWvPzeGHO9MSbOGBNljLnSGONbF/SspO8aY9KMMane4/8mScaYxcaYHG9ThGp5Rml8F+LHJI3u4vTPSvq0MWa6t5nDTyWttdYW9OBL+aOknxhjRnnrSjPG+LrqJcgTLMrlGcH5abuv3y3pCUkPGWOGe0eXzvc1l+gN73s/JulXxph0b10Zxpj266T+Ic96of9Wx6NFstYWSVoq6ZfGmEHeRhNjjDEXtztsuaS79eG0uWWnfA4A6AMEIwAII9baX0r6mjwNFUrlGaG4W5Kvm9mPJW2QtE3SdnmaF/zY+9xYSe9IqpNn9OkP1tr3vc89IE+gqjLGfKOD874j6XuSXpBUJM+ozS2nHuenX0t6RZ4pfbWS1kg61/vc0/JM2Tsiaaf3ufa+4f261kuqkPRzBe532bflmWq4xjuN7x15GjlIOhF6PpCn8cM/u3ifT0qK9tZfKel5edZ2+SyXJwCu6ORzAEAfMP6vuwUAAACAsxMjRgAAAAAcr6vORr1mjCmQVCvPPPZWa+3sYJ4PAAAAAHoiqMHIa4G1tiwE5wEAAACAHmEqHQAAAADHC3YwsvJ0HdpojPlCkM8FAAAAAD0S7Kl08621R7x7QrxtjNltrT2pHak3MH1BkuLj42dNmDAhyCUBAAAACFcbN24ss9amBfp9Q9au2xjzA0l11toHOztm9uzZdsOGDSGpBwAAAED4McZsDEZTt6BNpTPGxBtjEnwfy7Nb+I5gnQ8AAAAAeiqYU+mGSHrJGOM7zzPW2jeDeD4AAAAA6JGgBSNr7QFJ04L1/gAAAAAQKLTrBgAAAOB4BCMAAAAAjkcwAgAAAOB4BCMAAAAAjkcwAgAAAOB4BCMAAAAAjkcwAgAAAOB4BCMAAAAAjkcwAgAAAOB4BCMAAAAAjkcwAgAAAOB4BCMAAAAAjkcwAgAAAOB4BCMAAAAAjkcwAgAAAOB4BCMAAAAAjkcwAgAAAOB4BCMAAAAAjkcwAgAAAOB4BCMAAAAAjkcwAgAAAOB4BCMAAAAAjkcwAgAAAOB4BCMAAAAAjkcwAgAAAOB4BCMAAAAAjkcwAgAAAOB4BCMAAAAAjkcwAgAAAOB4BCMAAAAAjkcwAgAAAOB4BCMAAAAAjkcwAgAAAOB4BCMAAAAAjkcwAgAAAOB4BCMAAAAAjkcwAgAAAOB4BCMAAAAAjkcwAgAAAOB4BCMAAAAAjkcwAgAAAOB4BCMAAAAAjkcwAgAAAOB4BCMAAAAAjkcwAgAAAOB4BCMAAAAAjkcwAgAAAOB4BCMAAAAAjkcwAgAAAOB4BCMAAAAAjkcwAgAAAOB4BCMAAAAAjkcwAgAAAOB4BCMAAAAAjkcwAgAAAOB4BCMAAAAAjkcwAgAAAOB4BCMAAAAAjkcwAgAAAOB4BCMAAAAAjkcwAgAAAOB4BCMAAAAAjkcwAgAAAOB4BCMAAAAAjkcwAgAAAOB4BCMAAAAAjkcwAgAAAOB4BCMAAAAAjkcwAgAAAOB4BCMAAAAAjkcwAgAAAOB4BCMAAAAAjkcwAgAAAOB4BCMAAAAAjkcwAgAAAOB4BCMAAAAAjkcwAgAAAOB4BCMAAAAAjhf0YGSMiTDGbDbGLAn2uQAAAACgJ0IxYvQVSbtCcB4AAAAA6JGgBiNjTKakqyX9OZjnAQAAAIDeCPaI0cOSviXJHeTzAAAAAECPBS0YGWMWSyqx1m48w3FfMMZsMMZsKC0tDVY5AAAAANCpYI4YzZN0rTGmQNI/JC00xvzt1IOstY9aa2dba2enpaUFsRwAAAAA6FjQgpG19l5rbaa1NkvSLZLes9Z+IljnAwAAAICeYh8jAAAAAI4XGYqTWGuXSVoWinMBAAAAQHcxYgQAAADA8QhGAAAAAByPYAQAAADA8QhGAAAAAByPYAQAAADA8QhGAAAAAByPYAQAAADA8QhGAAAAAByPYAQAAADA8QhGAAAAAByPYAQAAADA8QhGAAAAAByPYAQAAADA8QhGAAAAAByPYAQAAADA8QhGAAAAAByPYAQAAADA8QhGAAAAAByPYAQAAADA8QhGAAAAAByPYAQAAADA8QhGAAAAAByPYAQAAADA8QhGAAAAAByPYAQAAADA8QhGAAAAAByPYAQAAADA8QhGAAAAAByPYAQAAADA8QhGAAAAAByPYAQAAADA8QhGAAAAAByPYAQAAADA8QhGAAAAAByPYAQAAADA8QhGAAAAAByPYAQAAADA8QhGAAAAAByPYAQAAADA8QhGAAAAAByPYAQAAADA8QhGAAAAAByPYAQAAADA8QhGAAAAAByPYAQAAADA8QhGAAAAAByPYAQAAADA8QhGAAAAAByPYAQAAADA8QhGAAAAAByPYAQAAADA8QhGAAAAAByPYAQAAADA8QhGAAAAAByPYAQAAADA8QhGAAAAAByPYAQAAADA8QhGAAAAAByPYAQAAADA8QhGAAAAAByPYAQAAADA8QhGAAAAAByPYAQAAADA8QhGAAAAAByPYAQAAADA8QhGAAAAAByPYAQAAADA8QhGAAAAAByPYAQAAADA8QhGAAAAAByPYAQAAADA8QhGAAAAAByPYAQAAADA8QhGAAAAAByPYAQAAADA8QhGAAAAAByPYAQAAADA8QhGAAAAABwvaMHIGBNjjFlnjNlqjMk1xvwwWOcCAAAAgN6IDOJ7N0laaK2tM8ZESVppjHnDWrsmiOcEAAAAgG4LWjCy1lpJdd5Po7x/bLDOBwAAAAA9FdQ1RsaYCGPMFkklkt621q4N5vkAAAAAoCeCGoystW3W2umSMiXNNcZMPvUYY8wXjDEbjDEbSktLg1kOAAAAAHQoJF3prLVVkt6XdEUHzz1qrZ1trZ2dlpYWinIAAAAA4CTB7EqXZoxJ8n4cK+kjknYH63wAAAAA0FPB7Eo3TNJfjDER8gSwf1lrlwTxfAAAAADQI8HsSrdN0oxgvT8AAAAABEpI1hgBAAAAQH9GMAIAAADgeAQjAAAAAI5HMAIAAADgeAQjAAAAAI5HMAIAAADgeAQjAAAAAI5HMAIAAADgeAQjAAAAAI5HMAIAAADgeAQjAAAAAI5HMAIAAADgeAQjAAAAAI5HMAIAAADgeAQjAAAAAI5HMAIAAADgeAQjAAAAAI5HMAIAAADgeAQjAAAAAI5HMAIAAADgeAQjAAAAAI5HMAIAAADgeAQjAAAAAI5HMAIAAADgeAQjAAAAAI5HMAIAAADgeAQjAAAAAI5HMAIAAADgeAQjAAAAAI5HMAIAAADgeH4FI2PMX/15DAAAAADCkb8jRpPaf2KMiZA0K/DlAAAAAEDodRmMjDH3GmNqJU01xtR4/9RKKpH0ckgqBAAAAIAg6zIYWWsfsNYmSPqFtXaQ90+CtXawtfbeENUIAAAAAEHl71S6JcaYeEkyxnzCGPOQMWZUEOsCAAAAgJDxNxg9IqnBGDNN0tcl7Zf0dNCqAgAAAIAQ8jcYtVprraTrJP3OWvt7SQnBKwsAAAAAQifSz+NqjTH3SrpD0oXGGJekqOCVBQAAAACh4++I0c2SmiR9xlpbLClT0i+CVhUAAAAAhJBfwcgbhv4uKdEYs1hSo7WWNUYAAAAAzgp+BSNjzMclrZP0MUkfl7TWGHNTMAsDAAAAgFDxd43RdyTNsdaWSJIxJk3SO5KeD1ZhAAAAABAq/q4xcvlCkVd5N14LAAAAAP2avyNGbxpj3pL0rPfzmyW9HpySAAAAACC0ugxGxpgcSUOstd80xtwgab73qQ/kacYAAAAAAGHvTCNGD0u6V5KstS9KelGSjDFTvM9dE9TqAAAAACAEzrROaIi1dvupD3ofywpKRQAAAAAQYmcKRkldPBcbyEIAAAAAoK+cKRhtMMZ8/tQHjTGfk7QxOCUBAAAAQGidaY3RVyW9ZIy5XR8GodmSoiV9NJiFAQAAAECodBmMrLXHJF1gjFkgabL34deste8FvTIAAAAACBG/9jGy1r4v6f0g1wIAAAAAfeJMa4wAAAAA4KxHMAIAAADgeAQjAAAAAI5HMAIAAADgeAQjAAAAAI5HMAIAAADgeAQjAAAAAI5HMAIAAADgeAQjAAAAAI5HMAIAAADgeAQjAAAAAI5HMAIAAADgeAQjAAAAAI5HMAIAAADgeAQjAAAAAI5HMAIAAADgeAQjAAAAAI5HMAIAAADgeAQjAAAAAI5HMAIAAADgeAQjAAAAAI5HMAIAAADgeAQjAAAAAI5HMAIAAADgeAQjAAAAAI5HMAIAAADgeEELRsaYEcaY940xO40xucaYrwTrXAAAAADQG5FBfO9WSV+31m4yxiRI2miMedtauzOI5wQAAACAbgvaiJG1tshau8n7ca2kXZIygnU+AAAAAOipkKwxMsZkSZohaW0ozgcAAAAA3RH0YGSMGSjpBUlftdbWdPD8F4wxG4wxG0pLS4NdDgAAAACcJqjByBgTJU8o+ru19sWOjrHWPmqtnW2tnZ2WlhbMcgAAAACgQ8HsSmckPS5pl7X2oWCdBwAAAAB6K5gjRvMk3SFpoTFmi/fPVUE8HwAAAAD0SNDadVtrV0oywXp/AAAAAAiUkHSlAwAAAID+jGAEAAAAwPEIRgAAAAAcj2AEAAAAwPEIRgAAAAAcj2AEAAAAwPEIRgAAAAAcj2AEAAAAwPEIRgAAAAAcj2AEAAAAwPEIRgAAAAAcj2AEAAAAwPEIRgAAAAAcj2AEAAAAwPEIRgAAAAAcj2AEAAAAwPEIRgAAAAAcj2AEAAAAwPEIRgAAAAAcj2AEAAAAwPEIRgAAAAAcj2AEAAAAwPEIRgAAAAAcj2AEAAAAwPEIRgAAAAAcj2AEAAAAwPEIRgAAAAAcj2AEAAAAwPEIRgAAAAAcj2AEAAAAwPEIRgAAAAAcj2AEAAAAwPEIRgAAAAAcj2AEAAAAwPEIRgAAAAAcj2AEAAAAwPEIRgAAAAAcj2AEAAAAwPEIRgAAAAAcj2AEAAAAwPEIRgAAAAAcj2AEAAAAwPEIRgAAAAAcj2AEAAAAwPEIRgAAAAAcj2AEAAAAwPEIRgAAAAAcj2AEAAAAwPEIRgAAAAAcj2AEAAAAwPEIRgAAAAAcj2AEAAAAwPEIRgAAAAAcj2AEAAAAwPEIRgAAAAAcj2AEAAAAwPEIRgAAAAAcj2AEAAAAwPEIRgAAAAAcj2AEAAAAwPEIRgAAAAAcj2AEAAAAwPEIRgAAAAAcj2AEAAAAwPEIRgAAAAAcj2AEAAAAwPEIRgAAAAAcj2AEAAAAwPEIRgAAAAAcj2AEAAAQhuqaWlXd0NLXZQBnDYIRAABAGPr289t051Pr+roM4KwR2dcFAAAAoPtyj1arsKJB1cdblBgb1dflAGGPESMAAIAw09Lm1qHK47JW2lRY2dflAGcFghEAAECYOVTRoDa3lSStK6jo42qAswPBCAAAIMzkl9VLkuKiI7SBYAQEBMEIAAAgzPiC0dVThmnroWo1trT1cUVA+CMYAQAAhJn8snolxkbpI+cMUXObW9sOV/d1SUDYIxgBAACEmYLyemWnxmtOVookaT3T6YBeC1owMsY8YYwpMcbsCNY5AAAAnCi/1BOMkuOjNTZ9oNblE4yA3grmiNFTkq4I4vsDAAA4TmNLm45WNyo7NV6SNCc7RZsKK090qQPQM0ELRtbaFZK4fQEAABBABeWexgtZ3mA0NytFtU2t2l1c05dlAWGPNUYAAABhpMDbkW50uxEjSVrPdDqgV/o8GBljvmCM2WCM2VBaWtrX5QAAAPRrB8pOHjHKSIrV8MQYrS+o7MuygLDX58HIWvuotXa2tXZ2WlpaX5cDAEBI7DhSrT3FtX1dBsJQQVm90hIGaOCAyBOPzclO0bqCClnLOiOgp/o8GAEA4ETfeG6rvvXCtr4uA2Eov6xe2YPjT3psTlaKSmubVFje0EdVAeEvmO26n5X0gaTxxpjDxpjPButcAACEk9Y2t/aX1mnHkWrVN7X2dTkIM/llDSc60vnMzWY/I6C3gtmV7lZr7TBrbZS1NtNa+3iwzgUAQDgprGhQS5tVm9tq88Gqvi4HYaS2sUVldU0n1hf55KQNVFJcFMEI6AWm0gEAEGJ5JXUnPl6XX96HlSDcFJR5psqdOmLkchnNHpVCAwagFwhGAACEmC8YZafGax13+NENB8o+/N451ZysZOWX1auktjHUZQFnBYIRAAAhlldSp6GDYnTJ+DRtPlil5lZ3X5eEMFFQ1iBjpFGD4057zref0QZGjYAeIRgBABBieSV1ykkfqHOzU9TU6tb2I9V9XRLCRH5ZnYYnxiomKuK05yYPT1RMlEvr2OgV6BGCEQAAIeR2W+0v9QSj2Vl0EkP35Jef3pHOJzrSpRkjkrWhkO8noCcIRgAAhFBRTaMamtuUkz5QqQMHaHRavNZzhx9+sNYqv7ROWamnT6PzmZOdop1Ha1Tb2BLCyoCzA8EIAIAQ2nesVpKUkz5QkjQ3K0XrCyrkdtu+LAthoLKhRTWNrcpOHdjpMXOykuW20ibawAPdRjACACCEfB3pfMFoTlaKahpbtccbmIDO5J/oSNf5iNHMkcmKcBlGIYEeIBgBABBC+0vrlBwXpcHx0ZKkudmsM4J/8k/sYdT5iFH8gEhNGj6INvBADxCMAAAIoX3HPI0XjDGSpMzkWA1LjKGTGM4ov6xOES6jzOTYLo+bk5WirYeq1NTaFqLKgLMDwQgAgBCx1irP25HOxxijOd51RtayzgidKyhr0MiUOEVFdH35NifL0wZ+B23ggW4hGAEAECLl9c2qamhRTnrCSY/PyU7RsZomHaxo6KPKEA4OlNUrq4ONXU81JytZkrQun41ege4gGAEAECKnNl7wmevdz4jpdOiMtVYFZfVdri/yGexrA886I6BbCEYAAITIvk6C0dj0gUqMjeJCFp06VtOk4y1tXXaka29uVoo20AYe6BaCEQAAIbK/pE5x0REanhhz0uMul2+dEVOf0LH8snpJXXeka4828ED3EYwAAAiRvJKTO9K1Nzc7Wfll9SqpbeyDytDf+YJRlr8jRt428BsYhQT8RjACACBE8krqlJPW8R3/OVm+C1lGjXC6gvJ6RUe6NDyx61bdPpnJsRo6KEbr+H4C/EYwAgAgBGoaW1Rc06gx6R0Ho8kZiYqNiqABAzp0oNTTkc7lOn20sSPGGM3OStb6fNrAA/6K7OsCAABwgv3exgtjOwlGUREuzRiZRDAKoMr6Zr23u0SSFOEycrmMIoxRhMsTHDwff/h4cnyUJg1P7OOqO1ZQXq8xafHdes3c7BQt2Vakw5XHNSLFvyl4gJMRjAAACIHOWnW3NycrRb95b59qGls0KCYqVKWdtX7z3j49uaqgW69552sXd/n/qC+0ua0Oljdo0cT0br1uTrs28AQj4MwIRgAAhEBeSZ2iI1wa2cUF6rnZKbJW2lhYqQXju3cRjNMt31OqC8YM1gM3TFGb28ptrdrcOvGx53PPf49UNerLz27W5oOV/S4YHa06ruY2t0andm/EaPyQBA2KidSGwgrdOCszSNUBZw+CEQAAIZBXUqes1DhFRnS+vHfGyGRFuozW51cQjHrpUEWDDpTV6/bzRmnU4DMHiukjrO55YZt2HKnWx2aPCEGF/jvg60jnx9fRnstlNDsrhemZgJ9ovgAAQAjkldZpbHpCl8fERkdockYiG70GwIp9pZKki8el+nV8hMto0vBB2n6kOphl9UiBbw+jbq4xkjzT6faX1qu8rinQZQFnHYIRAABB1tjSpkMVDZ12pGtvbnaKth6qVmNLWwgqO3ut2Fuq4YkxGtNJe/SOTM5I1M6iGrW2uYNYWffll9UrPjpCaQMHdPu1c7KSJYnNgwE/EIwAAAiyA6X1ctuuGy/4zMlKUXObW1sPVYWgsrNTS5tbq/PKddG4tA430+3MlIxENba4lVdaF8Tqui+/rF7ZafHd+lp8pmQmKjrSxSgk4AeCUZgrLK9XSz+7swUAOJnvQruzVt3tfXiHnwvZntpyqEq1Ta26aFxat143NdPTqnv74f41nS6/rL7b64t8BkRGaPqIJL6fAD8QjMLY9sPVWvDgMj264kBflwKvrYeq9Mb2or4uA0A/k1dSJ5eRsv3oKpYUF63xQxK0jqlPPbZib6lcRpo3xr/1RT7ZqQMVFx2hHf1onVFzq1uHKxu63ZGuvblZKco9WqP6ptYAVgacfQhGYarNbfXdf2+X20ovbznS1+VA0q6iGt322Brd/exmFZbX93U5APqR/SV1GpESp5ioCL+On5OdrE2FlWpz2yBXdnZasbdU00ckKTGue3tB9ccGDAcrGuS2UlYvgtGc7BS1ua02H2R6JtAVglGYembdQW09XK0LxgzW3mN12nustq9LcrRjNY36zFPrNTAmUhEuo0eW7e/rkoKitc0tNxdqQLftK6lVTjeaAMzJSlFdU6t2FdUEsaqzU0V9s7Ydqe72NDqf/taA4URHul4Eo5kjk+Qy0jqm0wFdIhiFodLaJv3fm7t1wZjBeviW6XIZacnWo31dlmM1NLfqs39Zr+rjLXrizjm6efYIvbDpsI5UHe/r0gLK7ba68Y8f6JvPb+vrUoCw0trmVn5ZvXKG+B+M5manSJLWsv9Mt63MK5O16nEwmprZvxow5AcgGCXERGnisEFaz/cT0CWCURh64I1damxp0/3XTVZ6QozOGz1Yr24rkrXcyQ+1NrfVV/6xRTuP1ui3t87QpOGJ+q9Lxsha6U/Lz65Ro7dyi7X1UJVe3XpUlfXNfV0OHODdXcf0szd293UZvXawokEtbbZbI0bDEmOVmRzLhWwPrNhbqsTYKE3LTOrR66dk9K8GDPnl9UqOi1JSXHSv3ufc7MHadLBStY0tAaoMOPsQjMLMmgPlenHTEX3hotEn2r5eM2248svqlXuUKReh9sDru/T2zmO6b/E5WjRxiCQpIylWN87M1D/WH1JJTWMfVxgYbrfVr9/dp9SBA9Tc5tYrjFCe1Zpb3br7mU1ac6C8T+v47Xt5+uPy/SoL840p95V4Rh78adXd3tzsFK0vqOCmVzdYa/WffaWan5OqCFf3W1tL/a8BQ35pfa/WF/ksnjZMTa1uvU6DIKBTBKMw0tLm1vf+vUMZSbG6e8HYE49fMWmoIl1GS7bxwy6U/rqmUH9ema87L8jSnfOyT3ruiwvGqLXNfdZ0DHwrt1i7i2v1vcUTNWn4ID2/8XBfl4QgWr2/TEu2Felr/9yiuj7qYlVc3agt3n07jMV3AAAgAElEQVR8Vu/v24DWW3k9DUZZKSqvb9aBMpq5+GvPsVodq2nSReO6142uvf7WgKGgvL5X0+h8ZoxI0ui0eH5+A10gGIWRx1fma19JnX547STFRn/Y2Sg5PlrzclK1ZNvRs+rOYl1Tq3719t5+2V70/T0l+v7LO7RoQrq+t/ic054fNThe103P0N/XHlR5mN/t9o0WjU6L1+Kpw/WxWZnafqRau4sZoTxbvb69SAMiXSqqadQv3uybqWxv7zomSYqOcGnVvrI+qSFQ9pfUaeigGCXEdK9D2hzvOiOm0/lvxd5SST1fX+TTXxowHG9uU1F1o7J7uIdRe8YYfWzWCK0vqDyxbgnAyQhGYeJI1XH9+p19+sg5Q3TpOUNOe/6aacN1uPL4iTusZ4MXNh7Wr9/d1+/ubu0qqtHdf9+kCUMH6Te3zuh0usZdC3LU2Nqmx1fmh7jCwPKNFn1l0VhFuIyunZ6hqAij5zf0r/8vCIyWNreW7jymKycP1afOz9LTawq1oQ86WS3NLdbo1HhdMj7Nu5g+fG/65JXWdXu0SJJGp8YrdWC01hGM/LZib5nGpg/UsMTYXr1Pf2nAUODd+iE7rffBSJJumJkhl/H8fgVwOoJRmLj/1VxZWX3/mtNHJyTpsklDFB3hOqum0y3Z5lnH8sKm/vMD3NeWOyEmSk/cOUfxAyI7PTYnfaCumjJMT39QqKqG8GxWcOpokSSlxEdr0YQh+veWI2rpJ+1sETgf7C9XVUOLrpoyTN+8fLyGJ8bq2y9sU2NLW8hqqD7eog/2l+uySUM1f2yqjlQd18GKhpCdP5Dcbqu8kp4FI2OMZo9KocWyn443t2ldQUWvR4uk/tOAwTeykxWAESNJGjIoRheNS9MLmw6zRxbQAYJRGHhv9zG9lXtMX140VpnJcR0eMygmSheNS9Nr24rOin1miqsbtb6gUpnJsdp2uFr7+sE+Te3bcj9+52wNTYw542vuXpCjuqZWPbmqIPgFBoFvtOjLC8eeNDL2sdmZKqtr1rI9pX1YHYLhjR1Fio+O0EXj0hQ/IFI/vWGK9pfW6/fv54Wshvd3l6jVbXXZpCGal+NZK7IyLzyn0xXVNKqhua1HwUjyTKc7XHlcRdVnV/v/YFiTX67mVndAglF/acAQiFbdp7ppVqaKqhu1en94/psCgolg1M81trTp+6/kakxavD43f3SXx14zbZiKaxq1obAyRNUFz2verjkPfXy6IlxGL2w60qf1dNSW2x8Thw3SR84ZoidX5Yddi9QTo0Wp8bpm2vCTnrt4XJpSBw7Q8xsP9VF1CIbWNrfeyj2mRROHKCbKs47x4nFpumFmhh5Ztj9km42+lVus9IQBmp6ZpNGp8RqWGKNVYRqMetp4wedc7zojptOd2Yq9pRoQ6Trxd9Yb/aUBQ0FZvdITBnQ5O6G7Lp04RINiIvUc06GB0xCM+rnfv5+nQxXH9aPrJys6suv/XZdOHKKYKNeJKWjh7LVtRzVx2CDNzU7RJePS9NLmvh32/2kHbbn99aWFOappbNXTHxQGqbrgWLrTO1q0aOxp66giI1y6YWaG3t1VEvbNJfChtfkVqqhv1lVThp70+PeuPkeJsVH69gvbgr4YvbGlTcv3luoj5wyRy2VkjNG8nFSt3l8elqPhvQ1GE4cN0sABkVrPdLozWrG3VHOzU06E+t6akpHU5w0Y8ssC05GuvZioCF03PUNv5Rar+nh43bADgo1g1I/tL63Tn5Yf0PXTh+uCMWduPRo/IFILJ6Tr9e1Ffd5JpzeOVB3XpoNVWjx1mCTpxlmZOlbT1Cd3jOubWvXrd/bp8U7acvtjamaSLh6XpsdX5quhuf912OuI22318Dsdjxb53DgzU61uq5e3hH8QDzcV9c366wcFuvGR1Zpx/9KATbN6bXuR4qIjdMn49JMeT46P1g+unaRth6uDPi105b4yNTS36fJJH4az+Tmpqmpo0c4QjVgFUl5JrZLjojQ4vmebc0a4jGaOStb6/PCfCRBMR6qOa39pvS4OwDQ6nymZg/q8AUOgWnWf6qZZmWpqdeu1s2hdMhAIBKN+ylqr77+cqwGRLv3v1RP9ft3iqcNVVtestWE87eJ17w9qXzBaOCFdg2IiQ9qEobC8Xj9aslPnPfCufvXOXl0xaWiHbbn99eVFOaqob9Yzaw8GsMrg6Wq0yGf80ARNzUzsd10Dz1aNLW16detRfe4v6zX3J+/oey/nqraxRdXHW/S3Nb0fjWxtc+utHcVaMCG9wzvui6cO06UT0/XLt/eosDx4rX6X7ixWQkykzhs9+MRjF4zxfByO64x8jReM6dlmo5I0NytZe47VqrI+PJu4hEKg2nS319cNGGoaW1RW1xyUYDQ1M1HjhgzUc0yHBk5CMAqBqoZmPbfhkDYWVvjd2WnJtiKtzCvTNy4fr/SEMy/y91kwPl3x0RFhPZ1uybajmpKRqFHeLjwxURG6ZtpwvZVbHNR1Om631fK9pfrMU+t1yYPL9JfVBbpkfLpe+O/z9cgnZvZ4F3VJmjUqReePHqw/rTgQ0u5ePeHPaJHPx2ZlamdRjXKP9o+NEM82bW6rlfvK9I3ntmr2j9/Rl57drB1HavTZ+dl64ysXaun/XKxLJw7Rs+sO9fr7al1Bhcrrm3X1lGEdPm+M0Y+un6wol0v3vrg9KO2zW9vcemdXiRZOSD9p6nD6oBiNGzIw7NYZWWu1r4cd6dqbk+VZM3M2rB8NlhV7SzV0UIzG9vLvur2+bsBQ4OtIF4RgZIzRTbMytflg1YnpngAIRkFXUd+sWx5do28+v003PvKBpv5gqT76h1X60ZKdem1bkYqrG097TW1ji360ZKcmZwzSJ84b1a3zxUZH6NJzhuiNHcVh2Ur5UEWDth6uPjFa5HPjrEw1trj1xvbigJ+ztrFFT63K16UPLdennlinbYer9aWFY7XqnoX67a0zNGtUSq/u9vp8aVGOSmub9K8N/fsOnT+jRT7XTBuu6AgXo0YBZK3VjiPV+slrO3X+A+/qE4+v1Vs7inXVlKF65vPnatU9C3XvVRM1cdggSdKdF2Spor5Zr27t3c2Q17cXKTYqQgtOmUbX3rDEWN1z1QSt3l8elO/jjYWVqqhv1mXnDD3tuXk5qVqX7//Npf6gvL5ZVQ0tGpPWu4v1aSOSFB3hYp1RJ1rb3FqZV6aLxqUG5Ge1T4TLaPLwRG3ro2Dk60g3OgjBSJKun5GhCJdx5M/v6oYW7Snu+2636H8C1+YEp6mob9Ztj61Rflm9Hrl9powx2nywUpsOVuqvawpPbPw5PDFGM0Yla+bIZM0alayXNh1WaV2THv3k7B6NUiyeOlwvbzmqlXllXV7k9Ee+fZiuOuWu9YwRnu5Uz286rI/PGRGQc+0vrdPTqwv0/MbDqm9u0/QRSXr45um6cspQDYgMzOLd9s4fPVizRyXrj8v265Y5I8/YTKMvdGe0SJKS4qL1kUlD9PKWo7r3yon98msKN39cfkA/f3O3oiKMLhmfro/OyNDCTqa3SdL5YwZr3JCBemp1gW6aldmjC8M2t9WbO45pwYQ0xUZ3/b1/65yRennLUf34tV1aMD5d6YP8H9E+k7dyjyk60qVLxp8+HWp+TqqeXFWgTQcr/Vpz2R/47sSPHZLQq/eJiYrQtBGJWrnPs9FtIC/+zwZbD1eptrE1oNPofCZnJOqZdYVqbXMrMiK0P9/yy+pljDQipeNtOnorPSHmRHOjb14+vlezIsKJtVaf/ct6bTlUpac/M1cX5ITHzxOEBlcxQVJR36zb/7xW+WX1+vOnZuvKKcN0xeShuveqiXruvy7Qjh9crn/fNU/3LT5HM0cla3NhpX60ZKeu//0q/eWDQt02d6Smj0jq0bkvGpeqhJhILdkafosqX9t+VNNHJJ32i8AYoxtnZWpdfoUO9XKjR7fb6svPbtaiXy7Xs+sO6fJJQ/XyXfP077vm6foZGUEJRZLna7h7YY6OVjfqxX60aW17vtGiLy3K8fuX5E2zMlVR36z3dpcEubqzX2NLmx77zwHNz0nV+u9cqsc+OVtXTRnWZZctY4zuvCBbuUdrejzVan1Bhcrqmk67IdERl8voZzdMUVOrW/e9nNuj83XEWqu3cot1YU5qh62J52anKMJlwmo6XW870rX30RmeaauP/edAr9/rbLN8b5lcxhOeA60vGzDkl9UrIyk2YF32OnKTt7nRin3O2ZPuxU1HtKGwUgNjIvX//rZReSWMHOFDBKMgqPSGogOldXrsk7N14djT72JFR7o0fUSSPjM/W7+7baZW37tIa+5dpD/cPlPfuGycvn3lhB6ff0BkhC6fNFRLc4vV1Bo+004Kyuq140jNadPofK6fkSFj1OsmDC9tPqJXth7VZ+dna/W9C/XQzdM1rYchtLsuHpemqZmJ+sOy/f2uc6Bn36I8z2jR1DOPFvlcmJOq9IQBjpyOEWivbj2qivpmfXHBGCXF+d/F7PoZwzUoJlJP9bBj3BvbizQg0uX3CPPotIH66qVj9WZusd7YHpgbMDuLanSk6rgum9RxO/yEmChNH5GklXnlATlfKOSV1CkuOkLD/dgM+kxunTtCV04eqp+/uUcbC5lS196KvaWampnUrX8z/urLBgwFQWjVfapFE4coOS7KMT+/q4+36IE3dmnGyCS9evd8DYiM0J1PrldpLdtOwINgFGCV9c267c9rtd8biroztD80MUZXTRmmuxeO1aCYqF7VsXjqMNU2tWr5nvC5C+Tb1LWzu9YZSbE6f/RgvbjpSI8Xftc3ternb+7WtBFJ+s5VE5U6cECP6+0JY4y+tHCsDlY0+NXmurGlTSv2lur+V3fqzifXqSyIewYt3XlMu4pq9KVFOd2aMuLZ0yhT7+8p4ZdLL1hr9dTqAo0fkqDz23Vk80dcdKRumTtSb+YWd7t1t9tt9caOYk/jlm5sIvn5C0dr0vBBuu+VXFU39L4pylu5x+Qynv3YOjMvJ1XbD1eFzd4rgehI52OM0c9vmqqMpFh96ZnNdKjzqmpo1rbDVUGZRid5GjDE90EDBmutDoQgGEVHunTd9Ay9nXssIP+O+7tfvb1XFfXN+tF1kzUiJU6Pf2q2yuqa9PmnN4TV+kUED8EogNqHoj93MxQF2rycVCXHRZ1YsxMOXt16VLNGJWt4Umynx9w4M1MHKxp6PGXoD8vyVFLbpO9fc45cfTSf+tKJ6ZowNEG/X5bX4aa1BWX1empVvj795DpNv3+pPvnEOv1tbaGW7SnVX4O0SaxntGhft0eLfG6alak2t9XLW44EoTpn2FBYqdyjNbpzXlaPLqTvOG+UrLXdbt298WClSmqbdOWU0xsedCUqwqWf3zhVFfXN+snrO7v12o4szS3W7FEpGtzFzYr5OalyW2nNgfAYNcorqVNOLxsvtDcoJkq/v22myuqa9bV/bQnLDW8DbWVemdxWunhccNaJRLiMJvVBA4aK+mbVNrYqa3Bwg5Hk+fnd3ObWK1uD//PbWqvnNx4+0XEvlHKPVuvpDwr0ifNGabJ3JHDaiCQ9fPMMbT1cpa//ayv/pkAwChTf9Ln+EIokz0XLFZOH6Z1dx3S8uf/fBckrqdPu4tpOp9H5XDF5qOKiI/RCD4b9D5Y36LH/5OuGGRmaOTK5p6X2mm/U6EBpvV7fXqTjzW16b/cxff/lHbr4F+/rkgeX6Qev7lRBeYNumTNST356jrbed5kWTkjX39ceDMr0yJ6OFvnkpA/UjJFJem7D4aC0cXaCp1YVKDE2StdPz+jR60ekxPWodfdr24oUHenSoi5GajozOSNRn79wtP614XCv1v4cLG/Q7uLaTqfR+UwfkaS46IiwWGdU29ii4ppGjQlg+2hJmpKZqO8unqj395TqUdYbacXeUiXERGpaZvCmQ0/OSNSuopqQTn/2daTLTgt+MJo0fJAmDE0IyXS69QWV+sZzW3XN71bq/T2hW5fqdnv2hkyOi9bXPzL+pOeumDxU/3vlRL22vUi/WLonZDWhfyIYBYAvFOX1YPpcMF0zdZgamtvCYlH8a9uKZEzn0+h84gdE6srJw/TatqJuD3v/9PVdinQZfeuKnq/fCpQrJg/VmLR4feel7Zp2/1J95qkN+ueGQxqTNlA/vHaSln/zEr3/jUv0g2snacH4dMVGR+jOC7JUVtek1wO0psOnt6NFPjfNytSeY7XacaQmgNU5w9Gq43ozt1i3zBlxxq5wXelu627PNLoiXTwuTQO7MY2uva9eOlbZqfG658Vtamhu7dF7LN3pacN/+aSuR62iI12am50SFhu97i/1XNgGovHCqe44b5SunjJMv3hrj6NbeFtrtWJvmebnpAa1Y1xfNGA4EYxCMGJkjNHHZo/Q1sPV2nssuI0InllbqISYSI1IjtNnnlqvR5btD8nNtBc3exoufPvKCUqMO32pwucuzNbt547UI8v26x/rwmMjdgQHwchr++Fq3fH4Wi14cJm+/q+t+tf6Q8ovqz/jP9iqhmZ94vEPQ9HF/SQUSdK5owcrdeCAsNjsdcm2o5qTlaIhfrT+vXFWhmqbWvVWrv97Gq3OK9ObucW6a0GOhgZgIXRvRbiMvnP1RI0aHK87zhulv352rrbcd5meuHOOPnVB1onNbdu7cGyqxqTF66nVgZ1O19vRIp/FU4drQKRLz7OTerf9bU2hrLXd3rfsVO1bd/tzsbH5UKWO1TR1uqmrP2KiIvSzG6boUMVx/XLp3h69x1u5xZo4bJBfbYnn56TqQGl9t9dShdo+7wVmIDcc9THG6IEbpygz2bPeqDyIaw97ylqrXy7do41B3JR2X0mdimsag34zckqGZzQqlA0Y8svqFekyykzufGp5IF03fbgig7ynUUV9s17fXqwbZ2bqhf++QFdPGaafv7lbX/7HlqDObKk+3qIHXt+lmSOTdNPMzA6PMcboh9dO0sXj0vSdf+/QfxzUpQ8nC7tg1Nzq1rPrDur93SUBmQt6pOq4/uefW3TN71Yq92iNxqTF6/09JfrWC9u04MFlmvvTd3XX3zfpqVX52nm05qQ1IVUNnpGifSV1evSOWf0qFEmei++rpwzVe7tLVNfUszu5obD3WK32ldSdcRqdz3nZg5WRFKsXNvk3H7q1za37l+xUZnKsPjs/uzelBtTCCUP06pfm63uLz9GFY9PO2JLV05Y5S1sPVWnzwcBcbARqtEiSEmOjPK3Ptx4Nq26Ifa2xpU3Prjuoj5wzpNf7lXS3dfdr24oVHeHSwom92+/s3NGD9YnzRuqJVfna1M3vzbK6Jm0orNRl5/g3lW+etyXzqn7enS6vtE7RES6NDNIeNL71RhUNzfpaP1wb8cH+cv32vTx98/mtQZuCtmKv5+I12MFodGq84qMjtD2E64wKyus1MiUuZHsnpQ4coAUT0vXipiNB2xz++Y2H1Nzm1m3njlRsdIR+e+sMffuKCVqy7ahufGS1Dlf2biuOzjy0dI8qG5p1/3WTu1xbHBnh0u9um6Gx6QP1xb9tCvroGfqnsApGJTWNuv3Pa3Tvi9v16afWa9FDy/XUqnzVNna/k0pNY4t+/uZuLXhwmV7fXqQvXjJGy755if78qTna+N1L9c7XLtJPPjpZ88YM1pZDVfrBqzt11W/+o+n3L9Wnn1ynR5btPykUXdJPN1JdPG24mlrdenfXsb4upVNLth6Vy3iml/nD5TL66IwMrdxXqmM1jWc8/tn1h7S7uFbfuWpiUPeDCIUbZmYqYUCknlpdEJD3W7K9SLuKavTlRWMD8gv4plmZqmpo0bu7+v/0zf7ilS1HVdnQojsvCExo97d1t28a3UXjUnvdBVOSvn3FBA0dFKNvP7+tW8H4nZ3HZO2Zp9H5jB+SoNSB0f1+ndH+kjplpQb3wnZyRqLuW3yOlu8t1SPL9wftPD3xxxUHFB3p0oHSev1zQ3BGkZfvLdWYtHhldNGwJxBc3gYMoQxGB0qD35HuVB+blamyuqYTgTOQ3G6rZ9cd0pysZI3zbnhsjNF/XzJGT3xqjg5VNuja360KeGOV3KPV+uuaQt3RruFCVxJiovTEnXMUGx2hT9PG25HCJhhtLKzQ4t+u1I4jNXr45un69S3TlRQXpR+8ulPnP/CefvBK7ok5uV1paXPr6Q8KdMkvlumRZfu1eMowvfeNS/StKyacuDgwxignPUG3nztKD98yQ6vuWaiV316gX908TYunDtfBigb9/M3d/T4USdKskckalhjj95qDULPWasn2Ip2bPVjpCf5PcbthZobcVvr35q5HjaoamvXQ0j06b3SK38GrP4sfEKmPzR6h17YV+RUKu9LS5tYvl+7RhKEJunZa70aLfOblpGpYYoyeC9KFULAdrTreYafAYLHW6snVBZowNEHnjU4JyHv627p7y+EqFVU36srJPZ9G115CTJR+8tHJ2ldSpz+87/9F+lu5xRqREquJwxL8Ot7lMjp/TKpW5pX160Yf+0rqNDbdv6+pN24/d6QWTx2mXy7do7X9pFvfrqIardhbqi8vzNHcrBT96u19AZ+10NjSpnX5FSFb0xvKBgxut1VheYOyQhyMFkxI1+D4aD23IfDT6T44UK78snrddu7IDs/78l3zlBwXpU/8ea2e/sC/qcBn4nZb3edtuPC1y8af+QVew5Ni9fin5qiivlmfe3pDWDSwQuD0+2BkrdXTHxTo5j+tUVx0hF666wJdPyND103P0EtfnKd/3zVPHzlniP6+tlALHlymTz+5Tsv3lp42rcBaq7d3HtPlD6/QfS/natyQgXr17vl66Obpft1tykyO00dnZOqBG6bo3a9foo3fvVSr71nYr0OR5LmIuHrKMC3fW9ov9/7YVVSrA6X1Wjytexdno9MGaubIJL2wqesuaA+/s0/Vx1t03+JJAdlLpD/45Pmj1Gat/r62dwtE/7n+kArLG/StK8YHrHV5hMvohpkZWr63VCW9DG6htrGwUhf93/v67r+3h+yc6/IrtKuoRnde0LMW3Z3xp3X3G9uLFBVhdKmfU9j8sXDCEF0/fbh+/36edhefuQlHXVOrVuWV67Jzhnbr65+fM1iltU3aVxK6xfDd0djSpkMVDQHvSNcRY4weuGGKRg2O15f/sTmoe53569EVBxQXHaE7zsvSvVdNUFldkx5bEdgOemvzK9TU6g5ZMJqamRiyBgzHaht1vKUt5CNGUREuXT8jQ+/uPqaKAO+T9czag0qKi+r0RszotIF66a55unhcmu57OVf3vLC911OyX9h0WBsLK3XPlROUGNu9UfEpmYn6za0ztO1wlf7nn7TGd5J+HYwaW9r09ee26r6Xc3XxuDS9fPd8TRg66KRjpo9I0q9unq5V9yzUVy8dq+1HavSpJ9bpI79arr9+UKD6plZtO1ylWx5do88/vUFG0uOfmq1nP3+epmSeeVi1M4MHDgj55qA9tXjacLW0WS3tRrOCUHlt+1FFuIyu8HMaTXs3zsrU3mN1nXZB23esVn9dU6hb547UOcMHdXhMOMpKjdfC8el6Zm1hj39xNDS36tfv7tPcrBQtCHC4v3FmptxWeukMo3n9SfXxFn352c1yW890j+6uk+mpp1YXKCkuStf1sEV3Z3ytu59Ze7DD7o3WWr2+vVgXjk3r9gXDmdx3zSQlxkbpW89vO+Pd9WV7StTc5vZ7Gp3Ph+uM+ud0uvyyerltcDrSdSTBu96osqGlzy/iDlc26JWtR3Xr3JFKjIvSjJHJunrqMD32nwMBvVmyYm+poiNdOi+7e5sh95RvGlYoGjCc6EgX4mAkeaZDt7RZvRLAPelKahv1Vm6xbpqZ2eV09kExUXrsk7N194Ic/XPDId36/9u77/AoqvWB49+TThqkkEIIhCSU0EtAOoh0UFFRsSFiQVGQi+gFL3q9lqvXir0joigIIipVqoCA1JBGSSCQEEJCqCmkn98fO+EXIIGU3WRD3s/zzJPN7O7sbM7OZM+c97zvF9sq/Zk5l53PGyv206WpB3eUkXDhWga19uWFEa1ZGXOCN1bur9Q2zOVkRi6rY1NJy6hdFxxrI6vtGCWdzuaOT7eweHcyUwY258ux4Vf9B+7j5sSUgS34a7op5M3F0Y4Xfo2h22truOWjv4hPy+SVUW1ZNaUvN4X5XjejB+XRoXF9Aj3r8buVFXvVWrM0MoWeIV5XLepYlpHtGuFgZ8PPu68c9tda8/LSWFwcbJk6qIU5dteqjOsVRHpmHssq2abf/HWEkxm5PDe0pdmPheCGroQ39WDhLsvVNDJnOIvWmucXR5F6Poe542/A192RF3+NtnhIXfLZC6yKOcGYrk2qlKK7LON6BnEmO5/fSgmjjTx2juSzFxhmgfBSTxcHXrqlDZHHzvHNNeY5/RGTipeLA12aVqyuWGMPZ4K8nK22YxRvjGSZs7jrtbRu5M5LN7dhU1w6H6+Pr7bXvdzszUcAGF8i0c1zQ1qSX1jErLVxZnudjQdP0i3I0yLHTmmqMwFDTXaMwvzdaRvgzkIzZqdbuPMYBUWae0oJo7ucjY1i2pCWfHJfZ/alZJjqHVUi2dY7q4sTLrSpUkTEQ72CeLBHU77YeJh3Vx+stvDd42cvsGRPMjMWRzHgnQ10fW0Nj87dyePf7arWcO+6yCo7RhsPnuTmjzaTeDqbrx8MZ8rAFuX+YDva2XJbp8b8+mQvFk/syYj2/kweEMqGZ/vzQPem1ZbhxZoopRjZvhF/xaebfXi8KmKOn+foqexKpwqu72zPoDBfftt7nLyCS78or9ufxqa4dKYMbFGpTpe16x3qTahP+dMyl3Q2O4/P/jzEwDAfwoPMM6/lcqO7NCY+LZO9Fri6unBnEh1fXs16M9Xnmr8jiWVRKTwzuCW9m3vz/PAwopPP86OFa1l8t9UU5vZAj6ql6C5Lcerub0v5jCyPSsHORjG4tWXm3Y1s78/AMF/eWX2gzAr3eQVFrGCzwXkAACAASURBVN+fxsAwX2wr8cWlV6g32w6ftlgGraqIS8vERkFwNRTnLOmeboHc2rER7605yNZD1T/f6Fx2PvN3JHJLh0aXhKg39XLhvhuasmBHEvFpVc/0dfzsBeLSMunbwrvK2yqv6kzAcCQ9C0c7G/zKUb7CEkZ3bkzM8fPEHq96TTpT0oVEegR7EVKBCwXD2/mzeGJPHO1sLybbmr05gfPlSLYVnXyO742EC20aVT4yCEzfn168uQ13dmnMB2vj+N/KA2bvHGmtSUjPYsGORKb+FEHv/62j5xvrmLIggqWRxwnycmHGsFY8O6QluxPP8t3WI2Z9fXEpq+slfLw+nge/2Y6vmxO/P9W7UtXYwfRh7tzEgzdHd2Dq4Ja4mSHrUm02sr0/hUWaxaWMrtSU3yOPY2ejKhxGU9IdXQI4nZXHhhIVtPMKinhlaSwhDV0s9qWzpimleLBnEJHHzrEn6WyFnvvphkNk5hbw7BDLFbod0d4fJ3sbsydhiE/L4MVfY7iQX8gT83axs4rFLeNSM/jP7zH0ae7NhL7BANzSoRHdgz15a9UBi11IuJBXyPwdiQxp42exjFplpe7WWrM8OoVeod6lFjo012u/Oqot9jY2TF8cWeoXia2HT5GRW8DgNpU7x/cK9SbTCJW2NofSMgn0dK72LJhKKf57WzuCvE3zjY6frd5aT9//fZTsvEIeM46lkiYNCMXZ3pY3Vhyo8usU15ip7mLq7RpXTwKGhHRTRjpzzf2sqFs6BmBva56aRhvjTnLszAXu637t0aLLhfm7s2ZqP94f0xEPZ3teXhpL9/+uZeaSqDJTaZsSLkRXOOHC1djaKP53R3vuu6EJn/15iFeW7jNL5yj1fA5Tf4rghv+u5ca3N/DPn6P488BJ2gXU5983t2bZ5N4X6xtO6BfCxP4h9G/ZkDdXHbBYanNhZR2jo6eyeWvVAUa2b8QvT/as9ows17PW/u50btKAV5ft41+/RJktQ1BOfiEfro1j6oKIChVc1FqzLNL05czDxaHSr9+3eUO8XR0vCaebsyWBI6eyeWFka+yv4xHC2zsF4FaOtMwlpZy7wJwtR7itUwAt/SyXMcvNyZ5bOjRiwY4ktidUrfNSLCe/kEk/RlDPwZalk3rTqH49xs/Zwb6Uyl3VzMkv5Kkf9uDqaMc7d3W4+CVEKcXLt7YlK7eANy0UV/5rRDJns/MZ1zPIItsvNqpTI+rXs7/kMxKdfJ6k0xeqVNS1PPzqO/H8iDC2HT7Nj9uv7CCvijmBs4PtxflCFdUj2AulrLOeUXxaZrWG0ZXk4mjHZ/d3ISevkPFzdpTrCrs55OQX8s1fCfRr0ZAw/yvndHq5OvJ4/xDW7EutUva8zNwC5m49ip+7Ey19LZ/1r6R2AZZPwJCemUtE0rkaCaMr5uniwMAwX5ZEJJc6R7Ei5v2diLerQ6VHpx3sbLi1YwCLJ/bi96d6M7ydPz/tPMbg9zZy75fbWBl94pKO6qLdx9ideJYZw8PMOn/SxsZ0seehXkHM/iuBF36NrtJcvvX70xj2/iaWR6XQI8SL/97WjjVT+7Fz5kA+vb8LD/VqRptG9S8ZTS++4KSA53+JtuqsnLWZVX1rPJ+Tz8wRYXwwpiPODnY1vTvXFaUU8x7pzqN9mvHD9kSGvLeRzXGVj88vzvI36L0/eWf1QX6PPM6gdzfy3baj5TpZ7D12jmNnLpS7qGtZ7GxtGNWxEev2p3EmK4+TGbl8sDaeAa18rD5jYFW5ONpxV3ggy6PKn7r7/TVxaA3/GGj5eVf/GtGaJp7OPPH9LpLNcOX6fyv3sy/lPG+Nbk+YvztzH+6Gs4MdY2dv5+ipa6fqv9yry2I5kJrBO3d1vCJVfAtfNx7qFcT8HUlmK6ZbTGvNnC1HCPN3p1szy4QyFnN2sOPuroGXpO5eFpWCrY1ikBmz0ZVlTNdAegR78fryfZdcOCkqMp0/+re8dmHjsni4ONC2UX02W9k8o4LCIhLSswj1rZmOEZg+v5/e34X4tEyenLe7WsINF+9OJj0z7+LIa2nG92qGn7sT/12xv1Jf6nLyC3nk2x3sP5Fh+oJYzXOFixMwRFooAUNGTj7jvtlOZm5+qaNu1emBHk05nZXHW6sqP8KXcu4C6/ancWd4IA52Vf+62a5xfd6+swPbZtzEP4e24uipbB7/fhf93trAJxviSUjP4o0V+wlv6sHtncyb0AaMsLqRrZnQL5jvtyUyY3FUhef75BUU8erSWB6aswMfN0eWTurN+2M6ce8NTQj1cb3mZ7qxhzPPDW3FxoMnWVzOIveiYqyqYxTs7cIjfYLrVGKE6lTPwZZ/jWjNosd74Ghvw/1f/82MxZEVLpCbkJ7F+Dk7eHTuTpzsbPnhkRtYO7U/HQMb8MKSaO7+YuvFycdlWRZ5HHtbxeAqhNEVu6M4i87e47y96gA5+YXMHBFW5e3WBhdTd18lLXOx+LRMftqZxH3dmxDo6Wzxfatfz54vxoaTV1DEhO+qVgti3f5UvvnrCON6Bl0Mr23s4cx3D3cjv7CIB77eXqHsRSujU/h+WyKP9Q2mXxnhOE8PbGEkYogx62TXbYdPs/9EBg+ZOUV3WUqm7tbaVNS1Z4hXlUZqy6s4lXR+UREzS1zh3JN0lpMZuVUKowVTON2exDNkmblGTlUkns4mr7CoxkaMivVu7s1/b2/Hprh0/vVLlEWvLhcWab7adJh2AfXpEVJ2lrh6DrY8M7gFe5POsjyqYllS8wqKmDhvN38nnObduzqYNc18eRUnYIi2wDyjnPxCHpu7i30pGXx6Xxc6NalYQhJz6xnizdgeTfl6c0KlC74u2JFEYZHmnq4VD6O7Gk8XB57oH8Kfz/bn8we60NTLmTdXHuDGtzdwNjuPl29ta7EwRKUU04e2YvIAU+a8ZxfuLXdo5ZH0LO74dAtfbU5gbI+mLHmyF6GVqHX2QPemhDf14JVlsVKA1gKsqmPk4iijRNWhS1NPlk/uw4S+wSzYkcSQ9zbyZzlOfNl5Bby1aj9D3tvIjiNnmDkijOVP96FnqDdNvExfUt8a3Z6DqZkMf38TH62LK/VKZVGRKYyur5lSBYf5uxPm784XGw/z064kHuoVRHANfympLk29XLiplQ/z/k68Zurud/44QD17W568MbSa9s6UrnjWmI7EHD9f5lyTa0k7n8O0hZGE+bszfdil86Ka+7rxzbiupGfmMnb2ds5lX7uTn3z2As8tiqRD4/pMu0oMuqujHc8PDyMq+ZxZEzHM2ZKAh7M9t3Q0T1HdaymZunt34lmOnspmuIXD6EoK8nbhmUEtWbs/7WJmzD9iTmBno6o8qtsr1Iv8Qs32Ks41M6eLGemqKVX31dwVHsjkAaH8tPOYRTPVrY5N5XB6FhP6XfvC5u2dG9PKz403V+2/ImlOWQqLNFN/imDd/jReHdXW7Onty8vGRtEmwPwJGAqLNFPmR7D18CnevrM9N7ayjmiH54eHEerjyjML91Z4vmVBYRELdiTRt0VDmnhZ5kKcna0NQ9r48cOj3Vn9j76M6xnECyNbW7w8h1KKqYNb8sygFizek8yUBRHXHJVdsieZER9sIvF0Np/d34WXb21b6dFyGxvFG3e0Jzu3kJd+j6nUNkTZrKpjJKqPk70tM4aH8fMTPXF2tOPB2dv556LIUuPRTTVPUhj4zp98vP4QI9v7s+6ZfjzSJ/iSOTxKKe4MD2TN1H4MauPL238c5OYPN7P3suQAe5LOcvxcToWLul7NHZ0DSD57AU9nBybd1Nxs260NxvVsxqmsPJbuLTt1996ks6yIPsEjfYKrvf7WTWG+TBvckl8jjvPlpooVeSwq0kz9aS/ZeQV8eE/HUv+RdGriwecPdOHQyUwe/nbHVUemCgqLePrHPRRp+OCeTtcM7zB3Ioak09msjk3lnm5NqnVifnHq7mcX7sW2iglPKmN872Z0CGzAS7/FcDorj1UxJ+gR4lXlCyNdgzxxsLNhixWF0xXPP6mO4q7l8Y9BLbi9UwBv/3GQJRaoLaa15vONh2ji6VyuenS2Norpw0xhUPP+vvZIt9aaf/0SxdLIFGYMa8V9N9RsQp12AeZNwKC1ZuaSaFbGnOCFka25rVPlau5YgpO9Le+P6ci57Hz++XPFLmytP3CSlHM53NvNvKNFZWnu68ZLt7ThoV7Nrv1gM5l0U3NmDGvF0sgUnvphd6kd/azcAqYt3MuUBRGE+buz/Ok+DDVDmYRQH1cm3xTKssgUq6xRWZtJx6iO69TEg6WTevNE/xAW7kpi8LsbL0mDHJ+Wwf1f/83Eebtxr2fPwsd78O7dHfG5ShrRhm6OfHxvZ74cG86Z7Dxu++QvXlkaS3aeKdxlaeRxHOxsGFjJjIOlGdUpAC8XB/41Igz3OpaBsFeo1zVTd7+5aj+eLg48WkNx6xP7hzCinT9vrNhfrtHJYl9sOszm+HT+fXObq4Yc9GnekFl3d2JX4hkmzttV5tW7D9bGsfPoGV67rS1Nva49udnciRi+33YUpRT3d6/eL3fFqbsPp2fRPdgTz2oIoyvJ1kbx5h3tycjJ57G5OzlyKtssnTMne1vCm3qw2YoSMMSnZuLn7mQ15yGlTFeXuwd78tyiSLZVIfFBaXYePcOexLM80qdZucth9GvRkF6hXnywNu6qySG01ry6bB/zdyQxaUAoE/qFmGu3K83cCRje+eMgP25PZGL/EB7uXX1f6surTaP6PDe0JatjU0tNolKWH/4+iq+7IzeFWcfol6VM6BfCiyNbsyomlce/33VJsoqY4+e4+aPN/Lz7GJMHhDL/se5mzUI6oV8IrfzceOHX6GpLslJeRUWa1PM5F2ty1SbSMRI42dvyz6Gt+GViL9zr2fHQnB1MW7iX15bFMnTWJqKOnePlW9uwdFJvulag7s2g1r6sntqPe7o14evNCQyZtZGNB0+yPCqF/i0amjWFurerIztnDuT2Sla4rs2KU3dHJZ9jd+KVqYs3xZ3kr/hTPHVjKK41FK6qlOKtO9vTwteNST/sLrO2TUl7k87y9qoDDG/nx5iugdd8/Ij2/rw2qh3rD5xk2sK9VyQB2XroFB+uj2d0l8YVCsUpTsSwYGfVEjFk5xXw4/ZEhrbxo5GFUnSXpTh1N1CtYXQltfRzY2L/0Iupw82V/KFXqDf7Us6TnmkdsfbxJzOtIoyuJAc7Gz6/P5wmXs48NnenWWoJFfv8z0N4ONtzZ5drH6PFlFLMGBbGmex8PttwqMzHvb82jq83JzCuZ5DVFOo2ZwKG2ZsT+Gh9PGO6BvLsEPOklraE8b2a0TvUm5eXxlxz/jCYRsY3HDzJ3eGB13Vm2GLjezfj1VFtWbc/jUfnmubTfrvlCLd9vIWs3ALmPXIDUwe3NHsdTXtbG94c3Z6TGbm8vtwyGVTLUlSkOXEuh51HTrNkTzIfrYtj+s+R3P/V3/R/az2tXlh5MQ351AURFZ7LXpOu/0+sKLcOgQ34fVJvnroxlF/2JPPlpgTu6NyY9dP6M7ZHUKUOancne167rR0LHuuOvY0NY2dvJ/V8LiOqmI2uNHU5acfF1N1bjlyyvqhI8+bKAwQ0qFepOhLm5Oxgx5djw7G1UTwyd+dVT5SZuQVMnr8HX3cnXr+tfbnb9t4bmvDsEFPY3n9+j7k4gnY6K48pC/bQzNuF/9zSpsL7/vTAFvi4VS0Rw5I9xzmfU8C4XkGVen5Vje7SmNdua8sdNXjxYOKNpiuc3Zp54mum4pW9jXTfW2qgoGlJZ7LyeP6XKKKSz1388mxN6jvb8824rjjY2TDumx1mmbQdl5rBmn1pPNgziHoOFQsNbRtQn1EdG/H15oRSSz18tekws9bEMbpLY14c2dpqzu/mSsCwZE8yLy+NZUgb3xrJsFcRNjaKd+7qgJO9LVMW7Lnm3LAFO5JQwN3VFEZnDe7v3pQ3R7dnc3w6vf+3jn//FkOvUC+WT+5DzxDLFSJu37gBj/YJ5sftiRYv6qy15tstR7jx7Q20fGEF3V9fy+jPtjJlQQRv/3GQNftSycgtoE1AfR7qHcQro9ryRP8QlkQkM/yDTew6at4Mr5Yi2Q7EJRztbJk2pCU3d2hEQVFRlatGF7sh2IvlT/fhw3VxbE84bdYwOmFKXHJ3eCBzthzhxPAw/OqbvnSuiD5BVPI53rmzA4521VtssjSBns58fF9nHvh6O/9YsJcvHuhSavagF5dEk3Q6mwUTelS4COnE/iGcycrjq80JeLo4MvmmUJ5btJczWfnMHte1UkleihMxPD0/gh+3J1Y4FM6UojuBNo3cCW9aM9mmHOxsanx+hqOdLYue6GnWbbYNqI+7kx1b4tO5pUP1JLQoqbBI8+P2RN7+4wAZOQWM79WMSQOqL8FJRQR6OvP1g125+4utPDJ3J/Mf7V7hDk1JX2w8jJO9DWN7BFXq+dOGtGR51Ane/eMgb93Z4eL6BTsSeXXZPoa19eON29vVWKHT0pgjAcP6A2lMW7iX7sGevD+mk9lHEizB192JN25vz+Pf7+Ld1QevSIRTLL+wiAU7k7ixpY/Fildbq7vCA3GwteGVpbHMHBHGw72bVUuHd8rAFqyMOcGMxZGseLpvlY7pspzPyeefiyJZEX2CbkGeDGnjR2OPesbiTECDemW+7k2tfJiyIIK7Pt/K5AHNefLGEKv+zFvvnoka1dLPzWydomJO9rY8O6QVCx/vKRkILWBsjyBT6m5jQnN+YRFv/3GAFr6ujLJATYfK6hnizcwRYazZl8qstXFX3P/LnmMs3pPM5JuaVyh0s5hSiueHh3FH58a8t+YgD83ZwZp9acwY3qpKn+mqJGLYeugUB1MzGVdNKbqtmaujnVlDOm1tFD1CvNgUl17tBQ93HT3DrR9vZuaSaFr5ubHi6T68MLK1VZ/fOgQ24IMxnYg8dpan5++p9Aho6vkclkQkc3d4YKXnrDX2cGZcryAW7T52sVDz73uPM31xFP1aNGTWmI5W+QWqXUB9Yo9XLgHDrqNneOL7XbT0c+PLseHVmoSlqoa29eOeboF8vvEQWw6VnvBkTWwqJzNyazxCoaaM6hTAzpkDq7X0TD0HW16/vR1HTmUza81Bs28/OvkcN3+4mT9iU5kxrBXzH+vO9GGtuL97U/q39CHUx/WqnbHwIE+WP92Hm9v7896ag4z5YhtJp7PNvp/mYn1nHCFEpTTxcuamVqa0zDn5hSzceYyE9CyeHdLqkurZ1mBczyDu7NKYD9bGsTL6/7PpHT2Vxcxfouka5MFTVUgrbmOj+N8d7RgY5suGAycZGObDuJ5BVdrniiZiyMotYGV0Cs/8tJcn5u3G08WBm2tgRKMu6B3qTfLZCyRW0z/b9Mxcnl24lzs+3UJ6Rh4f3tOJHx/tTgvfitckqQmD2/jx75Gt+SM2lVeXxVZqG7P/SqCwSPNIn6oldHmyfyjuTva8sWI/6/an8o8FEXRt6sln93exilHu0rQLqE9uQRFx5ZhvU9LB1AzGz9mBn7sTcx7qZtZ5ttXlhZGtaeblwtQFezmbfeUFonl/JxLQoB79WlzfSReupiYufvUM8eaeboF8uekwkceunGtcGVprvtt6hNs/2UJeQRE/TejOhH4hlRrBdXeyZ9aYTsy6uyMHTmQw/P1NFsmSaQ7We1lLCFFhD/UKYs2+VBbuOsaHa+Po0tSDgVaYFUgpxau3tSUuLZOpP+0lyNuFYG9XJv+4B1sbxSwzhJfY2drw0b2dWLjrGLe0b2SWf1bFiRi+2pzA3V0DryjCmHo+hzX7Ulkdm8qW+FPkFRZRv549A1r58GDPoFp1dbg26WXMM9ocn15mtsGiIk3i6WxiU84Te/w8iaezaerlTGt/d1o3cifQw/ma//ALCov4fttR3ll9kJz8Qib0C2bygOZWPUJUlnG9mpF4+gKz/0og0MOZ8RXIiHY+J58ftiUyvJ1/lYtF13e256kbQ3lt+T62HEonzN+dr8aFWyQcyFzaNTaNPEclnyPMv3w1c46dyWbs19txtLPhu4dvoKFb9ZZNMBdnBztmjenI7Z9s4flfovj43s4Xz61H0rPYHJ/OM4NaWN3FuLpg+rAw1u1P47lFkfw+qXeVEl9k5OQzY7EpTX7/lg15966OZslmOqpTAF2aevCPBRFMWRDBhgNpvDyqrdVk8QRQ1R16cDXh4eF6586dNb0bQtRaWmsGv7eRI6eyyC/U/DShB92aVTwcrbqkns/h5g8342RvS98W3ny/LZFP7+vMsBrKnFYembkF3PTOBnzcnFjyZC8OpmawOjaVNftSL2aqauLpzKDWvgxq7Ut4Uw+rDAe6nmit6fnGOjo38eDj+zqTk1/IgRMZFztBsSnn2Z9yniyjxpWtjcLP3YkT53MuhpK5OtrRys+N1o3cL3aWWvi6XezMbk84zYu/RrP/RAZ9mnsbKeStK/tcRRUWaSbO28WqmFQ6BjZgeDs/hrW9dmfn8z8P8fqK/fz+VO+LnYSqyMkvZOisjdjb2rBgQo9qTydfUUVFmvb/+YPbOwfw8q1tr/q4vcfOsnZfGj/vPkZWbgE/Pd6DVn6WLUBaHT7ZEM+bKw/w1uj23Bluykj4+vJ9fLU5gS3TB5gtuYqomNWxqTw6dyfTBrfgqQGVq+kYe/w8T/6wm8TT2TwzuAWP963cKNHVFBQW8cmGQ7y/Ng7/+k7Mursj4RUMnVdK7dJah5t1x5COkRDXne+3HWXmkmgGtPJh9riuNb0717Q78QxjPt9GXmER93QL5PXb29f0Ll3TrxHJPD0/Ai8XB05l5aEUdAxswMAwXwa39iXUx7XOzyWqbtMW7mVZZAqNPepx6GQmxVNnXB3tLnZ0Wvu7E+bvTnNfV5zsbcnJL+Rgagaxx8+zL8XUgdqXkkFmrqnmmo2CkIaueLs6svXwKQIa1OOFkWEMaeN33bRvTn4hc7YcYVlkysWEAu0b12dYW3+Gt/O7YgQur6CIPm+uI9THlXmPdDfbfmTk5ONgZ2O14XOXu+vzreQXFvHLxF6XrM/OK2BTXDpr96Wybv9J0jNzsbVRhDf1YPqwVleMMtdWhUWae7/cRnTyOZZN7oN/Ayd6vL6ObkGefPZAl5revTrtyR92szomld8n9aalX/nDe7XW/Lg9iZd+j8HD2Z4P7+ls8QuruxPPMGV+BMfOZDNpQHMmDQgt94VE6RgJIcrlQl4hLy+N4bG+ITTzvnYRU2uwNPI4y6NSePvODjg7WH9Yktaa5xZFciY7j4FhvgwI88HHTa6Q1qQt8em88Gs0zbxdjU6QG63969PYo16FrnYWFWmSzmRf0llKSM9ieDt/JvYPteoQr6pKOp3NiugUlkWdYG+SaZ5Ca393RrT3Z1hbP4IburJwZxLPLork2/Hd6NeiYQ3vcc15ZWks3287Ssx/hnAyM5e1+9JYuy+Vvw6dIq+gCDcnO/q39GFgmA/9WjSkgbN1j4JVxvGzFxg6ayPBDV15oHtTnlm4l7nju9G3Dn8urMHJjFwGvfcnZ7Pz8XFzJLihC8ENXQn2diHEx5UQb1cCPOpdEu6YlVvA879E8WvEcfo09+a9uzvi7Vo94Z4ZOfm89FssP+8+xiu3tuGBcma5lI6REEIIIarFsTPZrIw+wYroExfrj7Tyc+P8hXzc69mz4uk+182oWWUs2ZPMlAURhDR04dBJU8HqpkYCnIFhPnRt5lknipsujTzOUz/swcneBh83JzZM629V6dXrqrjUDFbvS+XwySwOnczk8Mkszl34/9qBDnY2BHk5E+ztSnBDF1bGnOBIehZTB7VgYv/QGmnD9fvT6N3cu9zHjaU6RtZ/aVYIIYQQ1aqxhzOP9AnmkT7BpJy7YOokRZ3gQGoGM62o4GpNuSHYE08XBzycHZg+LJCBYT6ENKx7IbQj2zdi/f6T/Lz7GPd0ayKdIivR3NeN5iWyZGqtOZ2Vx+H0LA4bHaVDJ7M4mJbBmn2peLk6MO+R7vQI8aqxfb6xlXUkipIRIyGEEEKUS15BEQ521/9IiCi/zNwCFu1M4s7wwFqZobGuyy8sQkGtSxIkI0ZCCCGEqFHSKRKXc3W0Y1yv8qd7F9alLoR8VoRF/xpKqaFKqQNKqXil1HRLvpYQQgghhBBCVJbFOkZKKVvgY2AY0Bq4RynV2lKvJ4QQQgghhBCVZckRo25AvNb6sNY6D5gP3GrB1xNCCCGEEEKISrFkxygASCrx+zFjnRBCCCGEEEJYlRpPvqCUegx4zPg1VykVXZP7IyrNG0iv6Z0QlSbtV3tJ29Vu0n61m7Rf7SVtV7u1tMRGLdkxSgYCS/ze2Fh3Ca31F8AXAEqpnZZIvScsT9qudpP2q72k7Wo3ab/aTdqv9pK2q92UUhap72PJULodQHOlVDOllAMwBvjNgq8nhBBCCCGEEJVisREjrXWBUuopYBVgC8zWWsdY6vWEEEIIIYQQorIsOsdIa70cWF6Bp3xhqX0RFidtV7tJ+9Ve0na1m7Rf7SbtV3tJ29VuFmk/pbW2xHaFEEIIIYQQotaw5BwjIYQQQgghhKgVrKJjpJQaqpQ6oJSKV0pNr+n9ESZKqSNKqSilVERx9g+llKdSarVSKs746WGsV0qpD4w2jFRKdS6xnQeNx8cppR6sqfdzvVNKzVZKpZVMeW/O9lJKdTE+D/HGc1X1vsPrWxnt95JSKtk4BiOUUsNL3DfDaIsDSqkhJdaXej41EuH8baxfYCTFEWaglApUSq1XSsUqpWKUUk8b6+X4qwWu0n5y/Fk5pZSTUmq7Umqv0Xb/MdaX+vdWSjkav8cb9weV2FaF2lRU3VXab45SKqHEsdfRWG/5c6fWukYXTIkZDgHBgAOwF2hd0/sliwY4Anhftu5NYLpxezrwP+P2cGAFoIDuwN/Gek/gsPHTw7jtUdPv7XpcgL5AZyDaEu0FbDceq4znDqvp93w9LWW030vAtFIe29o4bPO+/gAAB/pJREFUVzoCzYxzqO3VzqfAT8AY4/ZnwBM1/Z6vlwXwBzobt92Ag0YbyfFXC5artJ8cf1a+GMeDq3HbHvjbOE5K/XsDE4HPjNtjgAWVbVNZLNp+c4DRpTze4udOaxgx6gbEa60Pa63zgPnArTW8T6JstwLfGre/BUaVWD9Xm2wDGiil/IEhwGqt9Wmt9RlgNTC0une6LtBabwROX7baLO1l3Oeutd6mTWeauSW2JcygjPYry63AfK11rtY6AYjHdC4t9XxqXCEbACwynl/ysyCqSGudorXebdzOAPYBAcjxVytcpf3KIseflTCOoUzjV3tj0ZT99y55TC4CbjLap0JtauG3VWdcpf3KYvFzpzV0jAKApBK/H+PqJyRRfTTwh1Jql1LqMWOdr9Y6xbh9AvA1bpfVjtK+Nctc7RVg3L58vbC8p4yQgdnFoVhUvP28gLNa64LL1gszM0JzOmG68inHXy1zWfuBHH9WTyllq5SKANIwfSE+RNl/74ttZNx/DlP7yHeYGnJ5+2mti4+914xj7z2llKOxzuLnTmvoGAnr1Vtr3RkYBjyplOpb8k6j9y1pDWsJaa9a6VMgBOgIpADv1OzuiKtRSrkCPwNTtNbnS94nx5/1K6X95PirBbTWhVrrjkBjTCM8rWp4l0QFXN5+Sqm2wAxM7dgVU3jcP6trf6yhY5QMBJb4vbGxTtQwrXWy8TMN+AXTCSfVGJrE+JlmPLysdpT2rVnmaq9k4/bl64UFaa1TjX8aRcCXmI5BqHj7ncIUcmB32XphJkope0xfqudprRcbq+X4qyVKaz85/moXrfVZYD3Qg7L/3hfbyLi/Pqb2ke8wNaxE+w01wlu11joX+IbKH3sVPndaQ8doB9DcyCDigGky3G81vE91nlLKRSnlVnwbGAxEY2qb4mwfDwK/Grd/A8YaGUO6A+eMEJJVwGCllIcRhjDYWCeqh1nay7jvvFKquxGPPbbEtoSFFH+pNtyG6RgEU/uNMTIsNQOaY5pgWur51BitWA+MNp5f8rMgqsg4Jr4G9mmt3y1xlxx/tUBZ7SfHn/VTSjVUSjUwbtcDBmGaI1bW37vkMTkaWGe0T4Xa1PLvrG4oo/32l7igpDDNCSp57Fn23FlaRobqXjBlmTiIKS70XzW9P7JoMGVg2WssMcXtgikWdy0QB6wBPI31CvjYaMMoILzEtsZjmsgYDzxU0+/tel2AHzGFe+RjiqN92JztBYQbJ6dDwEcYBaJlsWj7fWe0T6TxD8G/xOP/ZbTFAUpk2SnrfGoc09uNdl0IONb0e75eFqA3pjC5SCDCWIbL8Vc7lqu0nxx/Vr4A7YE9RhtFAy9e7e8NOBm/xxv3B1e2TWWxaPutM469aOB7/j9zncXPncp4khBCCCGEEELUWdYQSieEEEIIIYQQNUo6RkIIIYQQQog6TzpGQgghhBBCiDpPOkZCCCGEEEKIOk86RkIIIYQQQog6TzpGQgghUEoVKqUilFLRSqnfi2tLVGI7jZRSi8y8b0eUUj+X+H20UmqOmbb9klJqmjm2JYQQonaTjpEQQgiAC1rrjlrrtsBp4MnKbERrfVxrPfraj6ywLkqp1hbYbqUZRQbl/6gQQlwn5IQuhBDicluBgOJflFLPKqV2KKUilVL/Mda9oZR6ssRjXlJKTVNKBSmloo11tkqpt0o8d4Kx/mOl1C3G7V+UUrON2+OVUq+VsU/vYCrAeInLR3yMEa8gY9mvlJqjlDqolJqnlBqolPpLKRWnlOpWYjMdlFJbjfWPXuN9BymlDiil5mIqGhhYsT+tEEIIayUdIyGEEBcppWyBm4DfjN8HA82BbkBHTCM3fYEFwF0lnnqXsa6kh4FzWuuuQFfgUaVUM2AT0Md4TABQPBLUB9hYxq79BHRWSoVW4O2EYupQtTKWe4HewDTg+RKPaw8MAHoALxrhgGW9b4z1n2it22itj1Zgf4QQQlgx6RgJIYQAqKeUigBOAL7AamP9YGPZA+zG1MForrXeA/gYnYgOwBmtddJl2xwMjDW2+zfghalTsQnoY4TGxQKpSil/TB2TLWXsXyHwFjCjAu8pQWsdpbUuAmKAtVprDUQBQSUe96vW+oLWOh1Yj6kzVOr7Nh5/VGu9rQL7IYQQohawq+kdEEIIYRUuaK07KqWcgVWY5hh9ACjgda3156U8ZyEwGvDjytEijOdO0lqvuuIOU3KHoZhGiDwxjThlaq0zrrKP32HqGEWXWFfApRf5nErczi1xu6jE70Vc+v9PX/Y6mjLet1IqCMi6yj4KIYSopWTESAghxEVa62xgMvCMUsoOUydpvFLKFUApFaCU8jEevgAYg6lztLCUza0CnlBK2RvPbaGUcjHu2wZMwdQx2oQpvG3TNfYtH3gP+EeJ1UeAzsb2OwPNKvJ+DbcqpZyUUl5Af2AHV3/fQgghrkMyYiSEEOISWus9SqlI4B6t9XdKqTBgq1IKIBO4H0jTWscopdyAZK11Simb+gpTyNpuZXrySWCUcd8mYLDWOl4pdRTTqNFVO0aGr4GZJX7/GVO4XgymcL2DFXy7AJGYQui8gVe01seB42W878JKbF8IIUQtoEzh1kIIIYQQQghRd0konRBCCCGEEKLOk46REEIIIYQQos6TjpEQQgghhBCizpOOkRBCCCGEEKLOk46REEIIIYQQos6TjpEQQgghhBCizpOOkRBCCCGEEKLOk46REEIIIYQQos77P5Zk/j1WdukUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1008x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "btch1 = 1\n",
    "loss_t = history['loss_temp']\n",
    "\n",
    "it     = [i*step for i in range(len(loss_t))]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "lt      = ax.plot(it, loss_t)\n",
    "ax.set(xlabel='Review Number', ylabel='Cost', title='Cost on each review')\n",
    "ax.axis([0, len(loss_t)*step  + 0.5, 0.0, 5.0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  0.31376548708568924\n",
      "valid loss:  0.2893654898830045\n"
     ]
    }
   ],
   "source": [
    "train_epoch = history['loss_epoch']\n",
    "valid_epoch = history['loss_valid']\n",
    "\n",
    "print('train loss: ', train_epoch[-1])\n",
    "print('valid loss: ', valid_epoch[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy:  0.7385999999999991\n",
      "valid accuracy:  0.7121333333333333\n"
     ]
    }
   ],
   "source": [
    "acc_train_epoch = history['acc_train']\n",
    "acc_valid_epoch = history['acc_valid']\n",
    "\n",
    "print('train accuracy: ', acc_train_epoch[-1])\n",
    "print('valid accuracy: ', acc_valid_epoch[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This lines are for plot error on each epoch\n",
    "\n",
    "#ep = np.arange(1, its + 1, 1)\n",
    "\n",
    "#train_epoch = history['loss_epoch']\n",
    "#valid_epoch = history['loss_valid']\n",
    "#fig, ax = plt.subplots(figsize=(14, 8))\n",
    "#l1 , l2   = ax.plot(ep, train_epoch, ep, valid_epoch)\n",
    "#ax.set(xlabel='Epoch', ylabel='Cost', title='Logistic Regression with L1 and L2 regularization')\n",
    "#ax.axis([0.8, its + 0.5, 0.1, 0.8])\n",
    "#plt.legend([l1, l2],[\"Training\",\"Validation\"])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This lines are for plot accuracy on each epoch\n",
    "\n",
    "#fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "#acc_train_epoch = history['acc_train']\n",
    "#acc_test_epoch  = history['acc_test']\n",
    "\n",
    "#l3, l4  = ax.plot(ep, acc_train_epoch, ep, acc_test_epoch)\n",
    "#ax.set(xlabel='Epoch', ylabel='Accuracy', title='Multiple Layer Perceptron')\n",
    "#ax.axis([0.8, its + 0.5, 0.68, 0.88])\n",
    "#plt.legend([l3, l4],[\"Train Accuracy\", \"Test Accuracy\"])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous section, we successfully trained a model to predict the sentiment of a movie review. Unfortunately, if we'd close this IPython notebook at this point, we'd have to go through the whole learning process again and again if we'd want to make a prediction on \"new data.\"\n",
    "\n",
    "So, to reuse this model, we could use the [`pickle`](https://docs.python.org/3.5/library/pickle.html) module to \"serialize a Python object structure\". Or even better, we could use the [`joblib`](https://pypi.python.org/pypi/joblib) library, which handles large NumPy arrays more efficiently.\n",
    "\n",
    "To install:\n",
    "conda install -c anaconda joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./net.pkl']"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Exercise 3: compare  with your Neural Network\n",
    "\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "joblib.dump(vectorizer, './vectorizer.pkl')\n",
    "joblib.dump(net,'./net.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us restart this IPython notebook and check if the we can load our serialized objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = joblib.load('./vectorizer.pkl')\n",
    "net        = joblib.load('./net.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading the `tokenizer`, `HashingVectorizer`, and the tranined logistic regression model, we can use it to make predictions on new data, which can be useful, for example, if we'd want to embed our classifier into a web application -- a topic for another IPython notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True : Good comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "False: Bad comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "100.00%\r",
      "Done     \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ True]])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = ['I loved this movie']\n",
    "m  = tokenizer(example[0])\n",
    "X = vectorizer.transform([m])\n",
    "net.predSentiment(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "100.00%\r",
      "Done     \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ True]])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = ['This movie was great!']\n",
    "m  = tokenizer(example[0])\n",
    "X = vectorizer.transform([m])\n",
    "net.predSentiment(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "100.00%\r",
      "Done     \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[False]])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = [\"I didn't like this movie\"]\n",
    "m  = tokenizer(example[0])\n",
    "X = vectorizer.transform([m])\n",
    "\n",
    "net.predSentiment(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "100.00%\r",
      "Done     \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[False]])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = ['I did not like this movie']\n",
    "m  = tokenizer(example[0])\n",
    "X = vectorizer.transform([m])\n",
    "net.predSentiment(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "100.00%\r",
      "Done     \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[False]])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = [\"I don't like this movie\"]\n",
    "m  = tokenizer(example[0])\n",
    "X = vectorizer.transform([m])\n",
    "net.predSentiment(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In complex sentences the result is not the correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "100.00%\r",
      "Done     \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ True]])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = [\"I love the actor but the history was the worst, I don't recommend this one\"]\n",
    "m  = tokenizer(example[0])\n",
    "X = vectorizer.transform([m])\n",
    "net.predSentiment(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
